---
title: "PLS_GARCH"
output: pdf_document
date: "2023-01-23"
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Implied Volatility vs. Call Price Surface

```{r}
rm(list=ls())
library(pls)
library(forecast)
library(car)
library(tseries)
library(rugarch)
library(Dowd)
library(moments)

# Import data
Data_impvol <- read.csv("/Users/benjye/Dropbox/Pricing/Data_R/Data_impvol.csv",
                     header=TRUE, stringsAsFactors = FALSE)

S_all <- Data_impvol[,1]
imp_all <- Data_impvol[,-c(1)]

# Start from 2009
start <- 1767
R_all <- diff(log(S_all))
R_all <- R_all[start:length(R_all)]
R_sq_all <- R_all^2
imp_all <- imp_all[-nrow(imp_all),]
imp_all <- imp_all[start:nrow(imp_all),]

# Split data and normalize it
N_test <- 1000
R_train <- R_all[1:(length(R_all)-N_test)]
imp_train <- imp_all[1:(length(R_all)-N_test),]
R_test <- R_all[(length(R_all)-N_test+1):length(R_all)]
imp_test <- imp_all[(length(R_all)-N_test+1):length(R_all),]

train_data <- cbind(R_train,imp_train)
test_data <- cbind(R_test,imp_test)
train_data <- scale(train_data,center=TRUE,scale=TRUE)
```

The implied volatility is not normal, but the $\chi^2$ test of Jarque Bera test, including the skewness and kurtosis is still better than the call price surface. Thus, IV is used for the following models.

```{r}
# IV data
imp_train_norm <- scale(imp_train,center=TRUE,scale=TRUE)

# Test whether the IV data is normal or not
Num_obs <- 10
qqnorm(imp_train_norm[,Num_obs],ylim=c(-3,3))
qqline(imp_train_norm[,Num_obs],lwd = 2)
hist(imp_train_norm[,Num_obs])
```

```{r}
# Jarque Bera test for normality
jarque.bera.test(imp_train_norm[,Num_obs])

# Find skewness and kurtosis
skew_imp <- apply(imp_train_norm,2,skewness)
kurt_imp <- apply(imp_train_norm,2,kurtosis)
sprintf('Mean of skewness (IV) is %f',mean(skew_imp))
sprintf('Mean of kurtosis (IV) is %f',mean(kurt_imp))
```

```{r}
# Import call price surface data
Data_all_cs <- read.csv("/Users/benjye/Dropbox/Pricing/Data_R/Date_all.csv",
                     header=FALSE, stringsAsFactors = FALSE)
start <- 1767
Date_all_cs <- Data_all_cs[start:nrow(Data_all_cs),1]
S_all_cs <- Data_all_cs[start:nrow(Data_all_cs),2]
cs_all <- Data_all_cs[start:nrow(Data_all_cs),-c(1,2)]

R_all_cs <- diff(log(S_all_cs))
R_all_cs <- R_all_cs[-1]
cs_all <- cs_all[2:nrow(cs_all),]

N_test <- 1000
R_train_cs <- R_all_cs[1:(length(R_all_cs)-N_test)]
cs_train <- cs_all[1:(length(R_all_cs)-N_test),]
R_test_cs <- R_all_cs[(length(R_all_cs)-N_test+1):length(R_all_cs)]
cs_test <- cs_all[(length(R_all_cs)-N_test+1):length(R_all_cs),]


cs_train_norm <- scale(cs_train,center=TRUE,scale=TRUE)
qqnorm(cs_train_norm[,Num_obs],ylim=c(-3,3))
qqline(cs_train_norm[,Num_obs],lwd = 2)
hist(cs_train_norm[,Num_obs])
```

```{r}
# Jarque Bera test, skewness and kurtosis from call price surface
jarque.bera.test(cs_train_norm[,Num_obs])
skew_cs <- apply(cs_train_norm,2,skewness)
kurt_cs <- apply(cs_train_norm,2,kurtosis)
sprintf('Mean of skewness (CS) is %f',mean(skew_cs))
sprintf('Mean of kurtosis (CS) is %f',mean(kurt_cs))
```

```{r}
# Difference between chi^2 test of IV and CS
jb_imp <- c()
jb_cs <- c()
for(i in 1:130){
  jb_imp <- rbind(jb_imp,jarque.bera.test(imp_train_norm[,i])$statistic)
  jb_cs <- rbind(jb_cs,jarque.bera.test(cs_train_norm[,i])$statistic)
}
sprintf('Difference between chi^2 test of IV and CS is %f',mean(jb_imp-jb_cs))
```

Using Augmented Dickey Fuller test, we conclude that the series are stationary under 90% confidence.

```{r}
# ADF test for IV training data
pval <- sapply(1:130,function(x) adf.test(imp_train[,x])$p.value) # p-value from ADF
pval[which.max(pval)]
```

```{r}
# Plot the most unstationary series
plot(imp_train[,which.max(pval)],type='l')
```

We fit PLS model for $R$, and by selecting the lowest MSE, 1 component is the best result. However, in scale factors, the third component in 3-component model contains the most information compared to PCR. Thus, we use the optimal component as 3.

```{r}
# Fit PLS model on R
fit <- plsr(formula = R_train~., data=data.frame(train_data), rescale = F, validation="CV",segment.type=c("consecutive"))

fit.cv <- pls::crossval(fit, segments = 10,segment.type = c("consecutive"))
mse_pls <- MSEP(fit.cv)

plot(c(1:20),mse_pls$val[2,1,2:21],'l',xlab='Number of Components',ylab='MSE'
     ,main='MSE vs number of components')

# Find the number of components with minimum MSE
which.min(mse_pls$val[2,1,])
```

```{r}
# Plot scale factors for PLS of R
V <- t(as.matrix(train_data[,2:ncol(train_data)])) %*% 
  as.matrix(train_data[,2:ncol(train_data)]) 
e <- eigen(V)
alpha <- apply(diag(train_data[,1]) %*% 
                as.matrix(train_data[,2:ncol(train_data)]) %*% e$vectors, 2, mean) / e$values
#K: component numbers
f_PLS_1 <- c()
for(K in 2:5){
  w <- sapply(1:K, function(k) sum(alpha^2*e$values^(k+1)))
  W <- matrix(0, K, K)
  for(l in 1:K)
  {
    W[,l] <- sapply(1:K, function(k) sum(alpha^2*e$values^(k+l+1)))
  }
  beta <- solve(W, w,tol = 1e-200)
  temp <- sapply(1:130, function(j) sum(beta*(e$values[j])^(1:K)))
  f_PLS_1 <- rbind(f_PLS_1,temp)
}

par(mfrow=c(2,2))
dev.off()
ms <- c(0.947,0.960,0.971,0.979,0.987,0.995,1.001,1.007,1.014,1.021)
plot(1:10,f_PLS_1[1,1:10],'l',xlab='ms',ylab='scale factor',ylim=c(-2,5.1),main='scale factor (tau = 0.082)',col='black',xaxt = "n")
lines(f_PLS_1[2,1:10],col='blue')
lines(f_PLS_1[3,1:10],col='green')
lines(f_PLS_1[4,1:10],col='red')
#lines(f_PLS_1[5,1:10],col='brown')
abline(h=1,lty='dashed')
legend('topright',lty = c(1,1,1,1),legend=c("2 component","3 component", "4 components","5 components"), col = c("black","blue","green","red"))
axis(1,at=1:10,label=ms)
```

The 3rd component has large value when the return $R$ has large volatility, and thus, a better capture of the return behavior.

```{r}
# Plot the 3rd component in the training IV
plot(train_data[,4],type='l',xlab='Date',ylab='3rd IV')
```

```{r}
# plot the return
plot(train_data[,1],type='l',xlab='Date',ylab='R')
```

```{r}
# Fit PLS of 3 comp
N_comp <- 3
fit_new <- plsr(formula = R_train~., data=data.frame(train_data),ncomp=N_comp, rescale = F, validation="CV",segment.type=c("consecutive"))

# Find PLS factor of training data
V_pls_train <- as.matrix(fit_new$scores)%*%diag(N_comp)

# Find PLS factor of test data
P_pls <- fit_new$projection

## Normalize test data
imp_norm <- (imp_test - t(t(rep(1,nrow(imp_test))))%*%t(apply(imp_train,2,mean)))/(t(t(rep(1,nrow(imp_test))))%*%t(apply(imp_train,2,sd)))
imp_norm <- imp_norm-rep(1,dim(imp_norm)[1])%*%t(fit_new$Xmeans)

V_pls_test <- as.matrix(imp_norm)%*%as.matrix(P_pls)
```

The PLS factor in training data is in general stationary, except factor 2.

```{r}
# Decide whether the PLS factors are stationary or not
for(i in 1:N_comp){
  print(adf.test(V_pls_train[,i]))
}
```

```{r}
# Plot the training PLS factor
for(i in 1:N_comp){
  plot(V_pls_train[,i],type='l',xlab='Date',ylab=paste0("PLS factor ",i))
}
```

```{r}
# Normalize PLS factors in training and test data
V_train_norm <- scale(V_pls_train,center=TRUE,scale=TRUE)
V_test_norm <- (V_pls_test - t(t(rep(1,nrow(V_pls_test))))%*%t(apply(V_pls_train,2,mean)))/(t(t(rep(1,nrow(V_pls_test))))%*%t(apply(V_pls_train,2,sd)))

# Combine traing and test data
V_norm <- rbind(V_train_norm,V_test_norm)
```

However, the normalized training + test data is stationary according to ADF test.

```{r}
# Plot the normalized PLS factor (training+test)
for(i in 1:N_comp){
  plot(V_norm[,i],type='l',xlab='Date',ylab=paste0("PLS factor ",i))
}
```

```{r}
# ADF test for training+test data
adf.test(V_norm[,1],k=10)
adf.test(V_norm[,2],k=10)
adf.test(V_norm[,3],k=10)
```

```{r}
# Prepare R with normalized training + test data
R_train_norm <- scale(R_train,center=TRUE,scale=TRUE)
R_test_norm <- (R_test-mean(R_train))/sd(R_train)
R_pls <- c(R_train_norm,R_test_norm)
```

```{r}
Acf(R_pls)
Pacf(R_pls)
```

First, the base model is ARMA(0,0)+GARCH(0,1) with external factors as the normalized PLS factors. The coefficients of PLS factors are all insignificant. In-sample MSE is 0.0001843, while out-of-sample MSE is 0.000137. The residuals are independent and heteroscedastic, but not normal. It passes the coverage test with the exceed of 5%, but does not pass the test for independence failure.

```{r}
# GARCH model with PLS factors of R
spec.sGARCH_pls <- ugarchspec(variance.model=list(model="sGARCH", 
                            garchOrder=c(0,1),external.regressors = as.matrix(V_norm)), 
                            mean.model=list(armaOrder = c(0,0),include.mean=TRUE,
                                            external.regressors = as.matrix(V_norm)), 
                            distribution.model="norm")
sGARCH_pls <- ugarchfit(R_pls, spec=spec.sGARCH_pls,out.sample=N_test-1)
sGARCH_pls
```

```{r}
# In-sample MSE
sprintf("In-sample MSE is %g",mean((sGARCH_pls@fit$residuals*sd(R_train))^2))
```

```{r}
# Out-of-sample
forecast_sGARCH_pls<-ugarchforecast(sGARCH_pls, data = R_pls, n.ahead = 1, n.roll = N_test-1,out.sample =N_test-1)
sigma_sGARCH_pls<-sigma(forecast_sGARCH_pls)
fitted_sGARCH_pls<-fitted(forecast_sGARCH_pls)
sprintf("Out-of-sample MSE is %g",mean(((t(fitted_sGARCH_pls)-R_pls[(length(R_pls)-N_test+1):length(R_pls)])*sd(R_train))^2))
sprintf("Out-of-sample mean of sd is %g",mean(sigma_sGARCH_pls))
```

```{r}
# 95% CI
plot(R_all[(length(R_all)-N_test+1):length(R_all)],type='l',xlab='Date',ylab='Return',main="Out-of-sample")
lines(t(fitted_sGARCH_pls)*sd(R_train)+mean(R_train),col='blue')
lines(t(fitted_sGARCH_pls)*sd(R_train)+mean(R_train)+1.96*t(sigma_sGARCH_pls)*sd(R_train),col='green')
lines(t(fitted_sGARCH_pls)*sd(R_train)+mean(R_train)-1.96*t(sigma_sGARCH_pls)*sd(R_train),col='green')
```

```{r}
# QQplot, Normality test
qqnorm(sGARCH_pls@fit$residuals)
qqline(sGARCH_pls@fit$residuals,lwd = 2)
jarque.bera.test(sGARCH_pls@fit$residuals)

# Autocorrelation test, heteroscedasticity
Box.test(sGARCH_pls@fit$residuals, lag = 10, type = "Ljung")
Box.test(sGARCH_pls@fit$residuals^2, lag = 10, type = "Ljung")
```

```{r}
# Coverage test 95%
roll_sGARCH_pls<-ugarchroll(spec=spec.sGARCH_pls, data=R_pls, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.05, keep.coef=TRUE)
report(roll_sGARCH_pls, type="VaR", VaR.alpha = 0.05, conf.level = 0.95) 
```

```{r}
# Coverage test 99%
roll_sGARCH_pls<-ugarchroll(spec=spec.sGARCH_pls, data=R_pls, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.01, keep.coef=TRUE)
report(roll_sGARCH_pls, type="VaR", VaR.alpha = 0.01, conf.level = 0.99) 
```

```{r}
# Coverage test 90%
roll_sGARCH_pls<-ugarchroll(spec=spec.sGARCH_pls, data=R_pls, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.1, keep.coef=TRUE)
report(roll_sGARCH_pls, type="VaR", VaR.alpha = 0.1, conf.level = 0.9) 
```

```{r}
# Coverage test 92.5%
roll_sGARCH_pls<-ugarchroll(spec=spec.sGARCH_pls, data=R_pls, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.075, keep.coef=TRUE)
report(roll_sGARCH_pls, type="VaR", VaR.alpha = 0.075, conf.level = 0.925)
```

```{r}
# Coverage test 97.5%
roll_sGARCH_pls<-ugarchroll(spec=spec.sGARCH_pls, data=R_pls, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.025, keep.coef=TRUE)
report(roll_sGARCH_pls, type="VaR", VaR.alpha = 0.025, conf.level = 0.975)
```

Next, we add the external regressors including the lagged terms of the latent factors.

```{r}
# Create lag terms
N_train <- nrow(V_norm)
lags <- 2
X_train_new <- V_norm[(lags+1):N_train,]
for(i in 1:lags){
  if(lags==0){
    break
  }else{
    temp <- V_norm[(lags+1-i):(N_train-i),]
    X_train_new <- cbind(X_train_new,temp)
  }
}

R_pls1 <- R_pls[(lags+1):N_train]


# eGARCH
spec.eGARCH_pls_n <- ugarchspec(variance.model=list(model="eGARCH", 
                            garchOrder=c(1,1),external.regressors = as.matrix(X_train_new[,1:6])), 
                            mean.model=list(armaOrder = c(1,1),include.mean=FALSE,
                                            external.regressors = as.matrix(X_train_new)), 
                            distribution.model="norm")
eGARCH_pls_n <- ugarchfit(R_pls1, spec=spec.eGARCH_pls_n,out.sample=N_test-1)
eGARCH_pls_n
```

```{r}
# In-sample MSE
sprintf('In-sample MSE is %g',mean((eGARCH_pls_n@fit$residuals*sd(R_train))^2))
```

```{r}
# Out-of-sample
forecast_eGARCH_pls_n<-ugarchforecast(eGARCH_pls_n, data = R_pls1,n.ahead = 1,n.roll = N_test-1,out.sample =N_test-1)
sigma_eGARCH_pls_n<-sigma(forecast_eGARCH_pls_n)
fitted_eGARCH_pls_n<-fitted(forecast_eGARCH_pls_n)
sprintf('Out-of-sample MSE is %g',mean(((t(fitted_eGARCH_pls_n)-R_pls1[(length(R_pls1)-N_test+1):length(R_pls1)])*sd(R_train))^2))
sprintf('Out-of-sample mean of sd is %g',mean(sigma_eGARCH_pls_n))
```

```{r}
mu <- eGARCH_pls_n@fit$fitted.values
plot(mu*sd(R_train)+mean(R_train),type='l')
```

```{r}
# 95% CI
plot(R_pls1[(length(R_pls1)-N_test+1):length(R_pls1)]*sd(R_train)+mean(R_train),type='l',ylab='Return',xlab='Date')
lines(t(fitted_eGARCH_pls_n)*sd(R_train)+mean(R_train),col='blue')
lines(t(fitted_eGARCH_pls_n)*sd(R_train)+mean(R_train)+1.96*t(sigma_eGARCH_pls_n)*sd(R_train),col='green')
lines(t(fitted_eGARCH_pls_n)*sd(R_train)+mean(R_train)-1.96*t(sigma_eGARCH_pls_n)*sd(R_train),col='green')
```

```{r}
# Coverage Test 95%
roll_GARCH_pls_n<-ugarchroll(spec=spec.eGARCH_pls_n, data=R_pls1, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.05, keep.coef=TRUE)
report(roll_GARCH_pls_n, type="VaR", VaR.alpha = 0.05, conf.level = 0.95) 
```

```{r}
# Coverage Test 99%
roll_GARCH_pls_n<-ugarchroll(spec=spec.eGARCH_pls_n, data=R_pls1, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.01, keep.coef=TRUE)
report(roll_GARCH_pls_n, type="VaR", VaR.alpha = 0.01, conf.level = 0.99) 
```

```{r}
# Coverage Test 90%
roll_GARCH_pls_n<-ugarchroll(spec=spec.eGARCH_pls_n, data=R_pls1, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.1, keep.coef=TRUE)
report(roll_GARCH_pls_n, type="VaR", VaR.alpha = 0.1, conf.level = 0.9) 
```

```{r}
# Coverage Test 92.5%
roll_GARCH_pls_n<-ugarchroll(spec=spec.eGARCH_pls_n, data=R_pls1, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.075, keep.coef=TRUE)
report(roll_GARCH_pls_n, type="VaR", VaR.alpha = 0.075, conf.level = 0.925) 
```

```{r}
# Coverage Test 97.5%
roll_GARCH_pls_n<-ugarchroll(spec=spec.eGARCH_pls_n, data=R_pls1, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.025, keep.coef=TRUE)
report(roll_GARCH_pls_n, type="VaR", VaR.alpha = 0.025, conf.level = 0.975) 
```

```{r}
# Autocorrelation and heteroscedasticity
Box.test(eGARCH_pls_n@fit$residuals, lag = 10, type = "Ljung")
Box.test(eGARCH_pls_n@fit$residuals^2, lag = 10, type = "Ljung")
jarque.bera.test(eGARCH_pls_n@fit$residuals)
```

Then, we use different distribution for the model.

```{r}
# Create lag terms
N_train <- nrow(V_norm)
lags <- 2
X_train_new <- V_norm[(lags+1):N_train,]
for(i in 1:lags){
  if(lags==0){
    break
  }else{
    temp <- V_norm[(lags+1-i):(N_train-i),]
    X_train_new <- cbind(X_train_new,temp)
  }
}

R_pls1 <- R_pls[(lags+1):N_train]


# eGARCH
spec.eGARCH_pls <- ugarchspec(variance.model=list(model="eGARCH", 
                            garchOrder=c(1,1),external.regressors = as.matrix(X_train_new[,1:6])), 
                            mean.model=list(armaOrder = c(1,1),include.mean=FALSE,
                                            external.regressors = as.matrix(X_train_new)), 
                            distribution.model="sged")
eGARCH_pls <- ugarchfit(R_pls1, spec=spec.eGARCH_pls,out.sample=N_test-1)
eGARCH_pls
```

```{r}
# In-sample MSE
sprintf('In-sample MSE is %g',mean((eGARCH_pls@fit$residuals*sd(R_train))^2))
```

```{r}
# Out-of-sample
forecast_eGARCH_pls<-ugarchforecast(eGARCH_pls, data = R_pls1, n.ahead = 1, n.roll = N_test-1,out.sample =N_test-1)
sigma_eGARCH_pls<-sigma(forecast_eGARCH_pls)
fitted_eGARCH_pls<-fitted(forecast_eGARCH_pls)
sprintf('Out-of-sample MSE is %g',mean(((t(fitted_eGARCH_pls)-R_pls1[(length(R_pls1)-N_test+1):length(R_pls1)])*sd(R_train))^2))
sprintf('Out-of-sample mean of sd is %g',mean(sigma_eGARCH_pls))
```

```{r}
# 95% CI
plot(R_pls1[(length(R_pls1)-N_test+1):length(R_pls1)]*sd(R_train)+mean(R_train),type='l',ylab='Return',xlab='Date')
lines(t(fitted_eGARCH_pls)*sd(R_train)+mean(R_train),col='blue')
lines(t(fitted_eGARCH_pls)*sd(R_train)+mean(R_train)+1.96*t(sigma_eGARCH_pls)*sd(R_train),col='green')
lines(t(fitted_eGARCH_pls)*sd(R_train)+mean(R_train)-1.96*t(sigma_eGARCH_pls)*sd(R_train),col='green')
```

```{r}
# Coverage Test 95%
roll_GARCH_pls<-ugarchroll(spec=spec.eGARCH_pls, data=R_pls1, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.05, keep.coef=TRUE)
report(roll_GARCH_pls, type="VaR", VaR.alpha = 0.05, conf.level = 0.95) 
```

```{r}
# Coverage Test 99%
roll_GARCH_pls<-ugarchroll(spec=spec.eGARCH_pls, data=R_pls1, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.01, keep.coef=TRUE)
report(roll_GARCH_pls, type="VaR", VaR.alpha = 0.01, conf.level = 0.99) 
```

```{r}
# Coverage Test 90%
roll_GARCH_pls<-ugarchroll(spec=spec.eGARCH_pls, data=R_pls1, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.1, keep.coef=TRUE)
report(roll_GARCH_pls, type="VaR", VaR.alpha = 0.1, conf.level = 0.9) 
```

```{r}
# Coverage Test 92.5%
roll_GARCH_pls<-ugarchroll(spec=spec.eGARCH_pls, data=R_pls1, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.075, keep.coef=TRUE)
report(roll_GARCH_pls, type="VaR", VaR.alpha = 0.075, conf.level = 0.925) 
```

```{r}
# Coverage Test 97.5%
roll_GARCH_pls<-ugarchroll(spec=spec.eGARCH_pls, data=R_pls1, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.025, keep.coef=TRUE)
report(roll_GARCH_pls, type="VaR", VaR.alpha = 0.025, conf.level = 0.975) 
```

```{r}
# Autocorrelation and heteroscedasticity
Box.test(eGARCH_pls@fit$residuals, lag = 10, type = "Ljung")
Box.test(eGARCH_pls@fit$residuals^2, lag = 10, type = "Ljung")
```

Based on MSE from cross-validation, the optimal number of PLS factors on $R^2$ is 2. However, the scale factors show that 5 components give more information than PCA.

```{r}
# PLS on R^2
R_sq_train <- R_train^2
R_sq_test <- R_test^2
train_data_2 <- cbind(R_sq_train,imp_train)
test_data_2 <- cbind(R_sq_test,imp_test)
train_data_2 <- scale(train_data_2,center=TRUE,scale=TRUE)

fit2 <- plsr(formula = R_sq_train~., data=data.frame(train_data_2), rescale = F, validation="CV",segment.type=c("consecutive"))

fit2.cv <- pls::crossval(fit2, segments = 5,segment.type = c("consecutive"))
mse_pls2 <- MSEP(fit2.cv)
plot(c(1:20),mse_pls2$val[2,1,2:21],'l',xlab='Number of Components',ylab='MSE'
     ,main='MSE vs number of components')
which.min(mse_pls2$val[2,1,])
```

```{r}
V <- t(as.matrix(train_data_2[,2:ncol(train_data_2)])) %*% 
  as.matrix(train_data_2[,2:ncol(train_data_2)]) 
e <- eigen(V)
par(mfrow=c(2,2))
alpha <- apply(diag(train_data_2[,1]) %*% 
                as.matrix(train_data_2[,2:ncol(train_data_2)]) %*% e$vectors, 2, mean) / e$values
#K: component numbers
f_PLS_2 <- c()
for(K in 2:6){
  w <- sapply(1:K, function(k) sum(alpha^2*e$values^(k+1)))
  W <- matrix(0, K, K)
  for(l in 1:K)
  {
    W[,l] <- sapply(1:K, function(k) sum(alpha^2*e$values^(k+l+1)))
  }
  beta <- solve(W, w,tol = 1e-200)
  temp <- sapply(1:130, function(j) sum(beta*(e$values[j])^(1:K)))
  f_PLS_2 <- rbind(f_PLS_2,temp)
}
```

```{r}
ms <- c(0.947,0.960,0.971,0.979,0.987,0.995,1.001,1.007,1.014,1.021,1.027)
plot(1:11,f_PLS_2[1,1:11],'l',xlab='ms',ylab='scale factor',ylim=c(-0.2,2.5),main='scale factor (tau = 0.082)',col='black',xaxt = "n")
lines(f_PLS_2[2,1:11],col='blue')
lines(f_PLS_2[3,1:11],col='green')
lines(f_PLS_2[4,1:11],col='red')
lines(f_PLS_2[5,1:11],col='brown')
abline(h=1,lty='dashed')
legend('topright',lty = c(1,1,1,1,1),legend=c("2 components","3 components","4 components","5 components","6 component"), col = c("black","blue","green",'red','brown'))
axis(1,at=1:11,label=ms)
```

PLS factors are all stationary for training + test data. First, we try the optimal component as 2.

```{r}
# PLS with R^2 
N_comp <- 2
fit_new2 <- plsr(formula = R_sq_train~., data=data.frame(train_data_2),ncomp=N_comp, rescale = F, validation="CV",segment.type=c("consecutive"))

V_pls_train2 <- as.matrix(fit_new2$scores)%*%diag(N_comp)

# Find test factors
P_pls2 <- fit_new2$projection
imp_norm <- (imp_test - t(t(rep(1,nrow(imp_test))))%*%t(apply(imp_train,2,mean)))/(t(t(rep(1,nrow(imp_test))))%*%t(apply(imp_train,2,sd)))
imp_norm <- imp_norm-rep(1,dim(imp_norm)[1])%*%t(fit_new2$Xmeans)
V_pls_test2 <- as.matrix(imp_norm)%*%as.matrix(P_pls2)

# Normalize factors
V_norm_train2 <- scale(V_pls_train2,scale=TRUE,center=TRUE)
V_norm_test2 <- (V_pls_test2-t(t(rep(1,nrow(V_pls_test2))))%*%t(apply(V_pls_train2,2,mean)))/(t(t(rep(1,nrow(V_pls_test2))))%*%t(apply(V_pls_train2,2,sd)))

# Combine training and test
V_norm2 <- rbind(V_norm_train2,V_norm_test2)
```

```{r}
# Create lag terms for PLS with R^2
lags <- 2
N_train <- nrow(V_norm2)

X_pls_2_all <- V_norm2[(lags+1):N_train,]
X_pls_1_all <- V_norm[(lags+1):N_train,]
for(i in 1:lags){
  if(lags==0){
    break
  }else{
    temp <- V_norm2[(lags+1-i):(N_train-i),]
    temp2 <- V_norm[(lags+1-i):(N_train-i),]
    X_pls_2_all <- cbind(X_pls_2_all,temp)
    X_pls_1_all <- cbind(X_pls_1_all,temp2)
  }
}


R_pls2 <- R_pls[(lags+1):N_train]


# GARCH
spec.eGARCH_pls2l <- ugarchspec(variance.model=list(model="eGARCH",
                    garchOrder=c(1,1),external.regressors = as.matrix(X_pls_2_all)), 
                    mean.model=list(armaOrder = c(1,1),include.mean=FALSE,external.regressors =
                                      as.matrix(X_pls_2_all)), distribution.model="norm")
eGARCH_pls2l <- ugarchfit(R_pls2, spec=spec.eGARCH_pls2l,out.sample=N_test-1)
eGARCH_pls2l
```

```{r}
# In-sample MSE
sprintf('In-sample MSE is %g',mean((eGARCH_pls2l@fit$residuals*sd(R_train))^2))
```

```{r}
# Out-of-sample
forecast_eGARCH_pls2l <-ugarchforecast(eGARCH_pls2l, data = R_pls2, n.ahead = 1, n.roll = N_test-1,out.sample =N_test-1)
sigma_eGARCH_pls2l<-sigma(forecast_eGARCH_pls2l)
fitted_eGARCH_pls2l<-fitted(forecast_eGARCH_pls2l)
sprintf('Out-of-sample MSE is %g',mean(((t(fitted_eGARCH_pls2l)-R_pls2[(length(R_pls2)-N_test+1):length(R_pls2)])*sd(R_train))^2))
sprintf('Out-of-sample mean of sd is %g',mean(sigma_eGARCH_pls2l))
```

```{r}
plot(R_all[(length(R_all)-N_test+1):length(R_all)],type='l',xlab='Date',ylab='Return')
lines(t(fitted_eGARCH_pls2l)*sd(R_train)+mean(R_train),col='blue')
lines(t(fitted_eGARCH_pls2l)*sd(R_train)+mean(R_train)+1.96*t(sigma_eGARCH_pls2l)*sd(R_train),col='green')
lines(t(fitted_eGARCH_pls2l)*sd(R_train)+mean(R_train)-1.96*t(sigma_eGARCH_pls2l)*sd(R_train),col='green')
```

```{r}
# Autocorrelaiton and heteroscedasticity for residuals
Box.test(eGARCH_pls2l@fit$residuals, lag = 10, type = "Ljung")
Box.test(eGARCH_pls2l@fit$residuals^2, lag = 10, type = "Ljung")
jarque.bera.test(eGARCH_pls2l@fit$residuals)
```

```{r}
# Coverage test 95%
roll_GARCH_pls2l <-ugarchroll(spec=spec.eGARCH_pls2l, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.05, keep.coef=TRUE)
report(roll_GARCH_pls2l, type="VaR", VaR.alpha = 0.05, conf.level = 0.95) 
```

```{r}
# Coverage test 99%
roll_GARCH_pls2l <-ugarchroll(spec=spec.eGARCH_pls2l, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.01, keep.coef=TRUE)
report(roll_GARCH_pls2l, type="VaR", VaR.alpha = 0.01, conf.level = 0.99) 
```

```{r}
# Coverage test 90%
roll_GARCH_pls2l <-ugarchroll(spec=spec.eGARCH_pls2l, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.1, keep.coef=TRUE)
report(roll_GARCH_pls2l, type="VaR", VaR.alpha = 0.1, conf.level = 0.9) 
```

```{r}
# Coverage test 92.5%
roll_GARCH_pls2l <-ugarchroll(spec=spec.eGARCH_pls2l, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.075, keep.coef=TRUE)
report(roll_GARCH_pls2l, type="VaR", VaR.alpha = 0.075, conf.level = 0.925) 
```

```{r}
# Coverage test 97.5%
roll_GARCH_pls2l <-ugarchroll(spec=spec.eGARCH_pls2l, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.025, keep.coef=TRUE)
report(roll_GARCH_pls2l, type="VaR", VaR.alpha = 0.025, conf.level = 0.975) 
```

Next, we try a different distribution.

```{r}
# Create lag terms for PLS with R^2
lags <- 2
N_train <- nrow(V_norm2)

X_pls_2_all <- V_norm2[(lags+1):N_train,]
X_pls_1_all <- V_norm[(lags+1):N_train,]
for(i in 1:lags){
  if(lags==0){
    break
  }else{
    temp <- V_norm2[(lags+1-i):(N_train-i),]
    temp2 <- V_norm[(lags+1-i):(N_train-i),]
    X_pls_2_all <- cbind(X_pls_2_all,temp)
    X_pls_1_all <- cbind(X_pls_1_all,temp2)
  }
}


R_pls2 <- R_pls[(lags+1):N_train]


# GARCH
spec.eGARCH_pls2l <- ugarchspec(variance.model=list(model="eGARCH",
                    garchOrder=c(1,1),external.regressors = as.matrix(X_pls_2_all)), 
                    mean.model=list(armaOrder = c(1,1),include.mean=FALSE,external.regressors =
                                      as.matrix(X_pls_2_all)), distribution.model="sged")
eGARCH_pls2l <- ugarchfit(R_pls2, spec=spec.eGARCH_pls2l,out.sample=N_test-1)
eGARCH_pls2l
```

```{r}
# In-sample MSE
sprintf('In-sample MSE is %g',mean((eGARCH_pls2l@fit$residuals*sd(R_train))^2))
```

```{r}
# Out-of-sample
forecast_eGARCH_pls2l <-ugarchforecast(eGARCH_pls2l, data = R_pls2, n.ahead = 1, n.roll = N_test-1,out.sample =N_test-1)
sigma_eGARCH_pls2l<-sigma(forecast_eGARCH_pls2l)
fitted_eGARCH_pls2l<-fitted(forecast_eGARCH_pls2l)
sprintf('Out-of-sample MSE is %g',mean(((t(fitted_eGARCH_pls2l)-R_pls2[(length(R_pls2)-N_test+1):length(R_pls2)])*sd(R_train))^2))
sprintf('Out-of-sample mean of sd is %g',mean(sigma_eGARCH_pls2l))

# Out-of-sample MSE is 0.000119006
```

```{r}
plot(R_all[(length(R_all)-N_test+1):length(R_all)],type='l',xlab='Date',ylab='Return')
lines(t(fitted_eGARCH_pls2l)*sd(R_train)+mean(R_train),col='blue')
lines(t(fitted_eGARCH_pls2l)*sd(R_train)+mean(R_train)+1.96*t(sigma_eGARCH_pls2l)*sd(R_train),col='green')
lines(t(fitted_eGARCH_pls2l)*sd(R_train)+mean(R_train)-1.96*t(sigma_eGARCH_pls2l)*sd(R_train),col='green')
```

```{r}
# Autocorrelaiton and heteroscedasticity for residuals
Box.test(eGARCH_pls2l@fit$residuals, lag = 10, type = "Ljung")
Box.test(eGARCH_pls2l@fit$residuals^2, lag = 10, type = "Ljung")
```

```{r}
# Coverage test 95%
roll_GARCH_pls2l <-ugarchroll(spec=spec.eGARCH_pls2l, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.05, keep.coef=TRUE)
report(roll_GARCH_pls2l, type="VaR", VaR.alpha = 0.05, conf.level = 0.95) 
```

```{r}
# Coverage test 99%
roll_GARCH_pls2l <-ugarchroll(spec=spec.eGARCH_pls2l, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.01, keep.coef=TRUE)
report(roll_GARCH_pls2l, type="VaR", VaR.alpha = 0.01, conf.level = 0.99) 
```

```{r}
# Coverage test 90%
roll_GARCH_pls2l <-ugarchroll(spec=spec.eGARCH_pls2l, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.1, keep.coef=TRUE)
report(roll_GARCH_pls2l, type="VaR", VaR.alpha = 0.1, conf.level = 0.9) 
```

```{r}
# Coverage test 92.5%
roll_GARCH_pls2l <-ugarchroll(spec=spec.eGARCH_pls2l, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.075, keep.coef=TRUE)
report(roll_GARCH_pls2l, type="VaR", VaR.alpha = 0.075, conf.level = 0.925) 
```

```{r}
# Coverage test 97.5%
roll_GARCH_pls2l <-ugarchroll(spec=spec.eGARCH_pls2l, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.025, keep.coef=TRUE)
report(roll_GARCH_pls2l, type="VaR", VaR.alpha = 0.025, conf.level = 0.975) 
```

Next, we try the optimal number of components as 5. Use normal first.

```{r}
#  PLS with R^2 
N_comp <- 5
fit_new2 <- plsr(formula = R_sq_train~., data=data.frame(train_data_2),ncomp=N_comp, rescale = F, validation="CV",segment.type=c("consecutive"))

V_pls_train2 <- as.matrix(fit_new2$scores)%*%diag(N_comp)

# Find test factors
P_pls2 <- fit_new2$projection
imp_norm <- (imp_test - t(t(rep(1,nrow(imp_test))))%*%t(apply(imp_train,2,mean)))/(t(t(rep(1,nrow(imp_test))))%*%t(apply(imp_train,2,sd)))
imp_norm <- imp_norm-rep(1,dim(imp_norm)[1])%*%t(fit_new2$Xmeans)
V_pls_test2 <- as.matrix(imp_norm)%*%as.matrix(P_pls2)

# Normalize factors
V_norm_train2 <- scale(V_pls_train2,scale=TRUE,center=TRUE)
V_norm_test2 <- (V_pls_test2-t(t(rep(1,nrow(V_pls_test2))))%*%t(apply(V_pls_train2,2,mean)))/(t(t(rep(1,nrow(V_pls_test2))))%*%t(apply(V_pls_train2,2,sd)))

# Combine training and test
V_norm2 <- rbind(V_norm_train2,V_norm_test2)
```

```{r}
# ADF test for training data
for(i in 1:N_comp){
  plot(V_norm2[,i],type='l',xlab='Date',ylab=paste0("PLS factor ",i),main='R^2')
  print(adf.test(V_norm2[,i],k=10))
}
```

The correlation between first and second component of $R$ and $R^2$ are highly correlated. Thus, we use PLS factors from $R^2$ alone in the following model.

```{r}
# Correlation between latent factors from R and R^2
V_norm_all <- cbind(V_norm,V_norm2)
cor_mat <- cor(V_norm_all)
abs(cor_mat)>0.9
```

```{r}
V_norm_all <- cbind(V_norm,V_norm2)
write.csv(V_norm_all,'V_norm_all.csv',row.names=FALSE)
```

Next, we try the eGARCH model with normal distribution. The in-sample MSE is 0.0001837, while the out-of-sample MSE is 0.0001286. The residuals are independent, and the model passes the coverage test.

```{r}
# Create lag terms for PLS with R^2
lags <- 2
N_train <- nrow(V_norm2)

X_pls_2_all <- V_norm2[(lags+1):N_train,]
X_pls_1_all <- V_norm[(lags+1):N_train,]
for(i in 1:lags){
  if(lags==0){
    break
  }else{
    temp <- V_norm2[(lags+1-i):(N_train-i),]
    temp2 <- V_norm[(lags+1-i):(N_train-i),]
    X_pls_2_all <- cbind(X_pls_2_all,temp)
    X_pls_1_all <- cbind(X_pls_1_all,temp2)
  }
}

# V_norm12 <- cbind(V_norm[,3],V_norm2)
# X_pls_2_all <- V_norm12[(lags+1):N_train,]
# for(i in 1:lags){
#   if(lags==0){
#     break
#   }else{
#     temp <- V_norm12[(lags+1-i):(N_train-i),]
#     X_pls_2_all <- cbind(X_pls_2_all,temp)
#   }
# }


R_pls2 <- R_pls[(lags+1):N_train]


# GARCH
spec.eGARCH_pls2_norm <- ugarchspec(variance.model=list(model="eGARCH",
                    garchOrder=c(1,1),external.regressors = as.matrix(X_pls_2_all[,1:5])), 
                    mean.model=list(armaOrder = c(1,1),include.mean=FALSE,external.regressors =
                                      as.matrix(X_pls_1_all)), distribution.model="norm")
eGARCH_pls2_norm <- ugarchfit(R_pls2, spec=spec.eGARCH_pls2_norm,out.sample=N_test-1)
eGARCH_pls2_norm
```

```{r}
# In-sample MSE
sprintf('In-sample MSE is %g',mean((eGARCH_pls2_norm@fit$residuals*sd(R_train))^2))
```

```{r}
# Out-of-sample
forecast_eGARCH_pls2_norm<-ugarchforecast(eGARCH_pls2_norm, data = R_pls2, n.ahead = 1, n.roll = N_test-1,out.sample =N_test-1)
sigma_eGARCH_pls2_norm<-sigma(forecast_eGARCH_pls2_norm)
fitted_eGARCH_pls2_norm<-fitted(forecast_eGARCH_pls2_norm)
sprintf('Out-of-sample MSE is %g',mean(((t(fitted_eGARCH_pls2_norm)-R_pls2[(length(R_pls2)-N_test+1):length(R_pls2)])*sd(R_train))^2))
sprintf('Out-of-sample mean of sd is %g',mean(sigma_eGARCH_pls2_norm))
```

```{r}
plot(R_all[(length(R_all)-N_test+1):length(R_all)],type='l',xlab='Date',ylab='Return')
lines(t(fitted_eGARCH_pls2_norm)*sd(R_train)+mean(R_train),col='blue')
lines(t(fitted_eGARCH_pls2_norm)*sd(R_train)+mean(R_train)+1.96*t(sigma_eGARCH_pls2_norm)*sd(R_train),col='green')
lines(t(fitted_eGARCH_pls2_norm)*sd(R_train)+mean(R_train)-1.96*t(sigma_eGARCH_pls2_norm)*sd(R_train),col='green')
```

```{r}
# Autocorrelaiton and heteroscedasticity for residuals
Box.test(eGARCH_pls2_norm@fit$residuals, lag = 10, type = "Ljung")
Box.test(eGARCH_pls2_norm@fit$residuals^2, lag = 10, type = "Ljung")
jarque.bera.test(eGARCH_pls2_norm@fit$residuals)
```

```{r}
# Coverage test 95%
roll_GARCH_pls2_norm<-ugarchroll(spec=spec.eGARCH_pls2_norm, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.05, keep.coef=TRUE)
report(roll_GARCH_pls2_norm, type="VaR", VaR.alpha = 0.05, conf.level = 0.95) 
```

```{r}
# Coverage test 99%
roll_GARCH_pls2_norm<-ugarchroll(spec=spec.eGARCH_pls2_norm, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.01, keep.coef=TRUE)
report(roll_GARCH_pls2_norm, type="VaR", VaR.alpha = 0.01, conf.level = 0.99) 
```

```{r}
# Coverage test 90%
roll_GARCH_pls2_norm<-ugarchroll(spec=spec.eGARCH_pls2_norm, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.1, keep.coef=TRUE)
report(roll_GARCH_pls2_norm, type="VaR", VaR.alpha = 0.1, conf.level = 0.9) 
```

```{r}
# Coverage test 92,5%
roll_GARCH_pls2_norm<-ugarchroll(spec=spec.eGARCH_pls2_norm, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.075, keep.coef=TRUE)
report(roll_GARCH_pls2_norm, type="VaR", VaR.alpha = 0.075, conf.level = 0.925) 
```

```{r}
# Coverage test 97.5%
roll_GARCH_pls2_norm<-ugarchroll(spec=spec.eGARCH_pls2_norm, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.025, keep.coef=TRUE)
report(roll_GARCH_pls2_norm, type="VaR", VaR.alpha = 0.025, conf.level = 0.975) 
```

Then, we use sged as distribution.

```{r}
# Create lag terms for PLS with R^2
lags <- 2
N_train <- nrow(V_norm2)

X_pls_2_all <- V_norm2[(lags+1):N_train,]
X_pls_1_all <- V_norm[(lags+1):N_train,]
for(i in 1:lags){
  if(lags==0){
    break
  }else{
    temp <- V_norm2[(lags+1-i):(N_train-i),]
    temp2 <- V_norm[(lags+1-i):(N_train-i),]
    X_pls_2_all <- cbind(X_pls_2_all,temp)
    X_pls_1_all <- cbind(X_pls_1_all,temp2)
  }
}

# V_norm12 <- cbind(V_norm[,3],V_norm2)
# X_pls_2_all <- V_norm12[(lags+1):N_train,]
# for(i in 1:lags){
#   if(lags==0){
#     break
#   }else{
#     temp <- V_norm12[(lags+1-i):(N_train-i),]
#     X_pls_2_all <- cbind(X_pls_2_all,temp)
#   }
# }


R_pls2 <- R_pls[(lags+1):N_train]


# GARCH
spec.eGARCH_pls2 <- ugarchspec(variance.model=list(model="eGARCH",
                    garchOrder=c(1,1),external.regressors = as.matrix(X_pls_2_all[,1:5])), 
                    mean.model=list(armaOrder = c(1,1),include.mean=FALSE,external.regressors =
                                      as.matrix(X_pls_1_all)), distribution.model="sged")
eGARCH_pls2 <- ugarchfit(R_pls2, spec=spec.eGARCH_pls2,out.sample=N_test-1)
eGARCH_pls2
```

```{r}
# In-sample MSE
sprintf('In-sample MSE is %g',mean((eGARCH_pls2@fit$residuals*sd(R_train))^2))
```

```{r}
# Out-of-sample
forecast_eGARCH_pls2<-ugarchforecast(eGARCH_pls2, data = R_pls2, n.ahead = 1, n.roll = N_test-1,out.sample =N_test-1)
sigma_eGARCH_pls2<-sigma(forecast_eGARCH_pls2)
fitted_eGARCH_pls2<-fitted(forecast_eGARCH_pls2)
sprintf('Out-of-sample MSE is %g',mean(((t(fitted_eGARCH_pls2)-R_pls2[(length(R_pls2)-N_test+1):length(R_pls2)])*sd(R_train))^2))
sprintf('Out-of-sample mean of sd is %g',mean(sigma_eGARCH_pls2))
```

```{r}
mu_train <- fitted(eGARCH_pls2)
mu_train <- drop(coredata(mu_train))
sigma_train <- sigma(eGARCH_pls2)
sigma_train <- drop(coredata(sigma_train))
plot(R_all[1:(length(R_all)-N_test)],type='l',xlab='Date',ylab='Return',col='red')
lines(mu_train*sd(R_train)+mean(R_train),col='blue')
lines(mu_train*sd(R_train)+mean(R_train)+1.96*sigma_train*sd(R_train),col='green')
lines(mu_train*sd(R_train)+mean(R_train)-1.96*sigma_train*sd(R_train),col='green')
```

```{r}
plot(R_all[(length(R_all)-N_test+1):length(R_all)],type='l',xlab='Date',ylab='Return',col='red')
lines(t(fitted_eGARCH_pls2)*sd(R_train)+mean(R_train),col='blue')
lines(t(fitted_eGARCH_pls2)*sd(R_train)+mean(R_train)+1.96*t(sigma_eGARCH_pls2)*sd(R_train),col='green')
lines(t(fitted_eGARCH_pls2)*sd(R_train)+mean(R_train)-1.96*t(sigma_eGARCH_pls2)*sd(R_train),col='green')
```

```{r}
# Autocorrelaiton and heteroscedasticity for residuals
Box.test(eGARCH_pls2@fit$residuals, lag = 10, type = "Ljung")
Box.test(eGARCH_pls2@fit$residuals^2, lag = 10, type = "Ljung")
```

```{r}
# Coverage test 95%
roll_GARCH_pls2<-ugarchroll(spec=spec.eGARCH_pls2, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.05, keep.coef=TRUE)
report(roll_GARCH_pls2, type="VaR", VaR.alpha = 0.05, conf.level = 0.95) 
```

```{r}
# Coverage test 99%
roll_GARCH_pls2<-ugarchroll(spec=spec.eGARCH_pls2, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.01, keep.coef=TRUE)
report(roll_GARCH_pls2, type="VaR", VaR.alpha = 0.01, conf.level = 0.99) 
```

```{r}
# Coverage test 90%
roll_GARCH_pls2<-ugarchroll(spec=spec.eGARCH_pls2, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.1, keep.coef=TRUE)
report(roll_GARCH_pls2, type="VaR", VaR.alpha = 0.1, conf.level = 0.9) 
```

```{r}
# Coverage test 92.5%
roll_GARCH_pls2<-ugarchroll(spec=spec.eGARCH_pls2, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.075, keep.coef=TRUE)
report(roll_GARCH_pls2, type="VaR", VaR.alpha = 0.075, conf.level = 0.925)
```

```{r}
# Coverage test 97.5%
roll_GARCH_pls2<-ugarchroll(spec=spec.eGARCH_pls2, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=252, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.025, keep.coef=TRUE)
report(roll_GARCH_pls2, type="VaR", VaR.alpha = 0.025, conf.level = 0.975) 
```

### Compare distribution of $R$.

```{r}
Data_sim_RNN <- read.csv("~/Dropbox/Pricing/Data_R/RNN_simp.csv")
Data_RNN <- read.csv("~/Dropbox/Pricing/Data_R/RNN3.csv")

end <- 1500
num <- 10000

mu_sim_RNN <- Data_sim_RNN$mu
sigma_sim_RNN <- Data_sim_RNN$sigma
set.seed(1000)
x_sim_RNN <- sapply(1:end,function(i) rnorm(num,mean=mu_sim_RNN[i],sd=sigma_sim_RNN[i]))
x_sim_RNN <- c(x_sim_RNN) 

mu_norm_RNN <- Data_RNN$mu
sigma_norm_RNN <- Data_RNN$sigma
set.seed(1000)
x_norm_RNN <- sapply(1:end,function(i) rnorm(num,mean=mu_norm_RNN[i],sd=sigma_norm_RNN[i]))
x_norm_RNN <- c(x_norm_RNN) 
```

```{r}
library(fGarch)
mu_norm <- fitted(eGARCH_pls2_norm)
#mu_norm <- drop(coredata(mu_norm))
sigma_norm <- sigma(eGARCH_pls2_norm)
#sigma_norm <- drop(coredata(sigma_norm))
set.seed(1000)
x_norm <- sapply(1:end,function(i) rnorm(num,mean=mu_norm[i],sd=sigma_norm[i]))
x_norm <- c(x_norm) 

skew <- 0.872
shape <- 1.54
mu <- fitted(eGARCH_pls2)
mu <- drop(coredata(mu))
sigma <- sigma(eGARCH_pls2)
sigma <- drop(coredata(sigma))
set.seed(1000)
x <- sapply(1:end, function(i) rsged(num,mean=mu[i],sd=sigma[i],nu=shape,xi=skew))
x <- c(x)

# mu_t_RNN <- -0.741
# sigma_t_RNN <- 1.877
# dof <- 1.410
# x_t_RNN <- rt(10000,df=dof)*sigma_t_RNN+mu_t_RNN

# hist(R_pls2,probability=T,nclass=(max(R_pls2)-min(R_pls2))*5+1,ylim=c(0,0.6))
plot(density(R_pls2[1:end],bw=0.2), col=c(1), lwd=2, type='l',main='Distribution',xlab='Normalized R')
lines(density(x_norm,bw=0.2),col=c(2), lwd=1)
lines(density(x,bw=0.2),col=c(3), lwd=1)
lines(density(x_sim_RNN,bw=0.2),col=c(4), lwd=1)
lines(density(x_norm_RNN,bw=0.2),col=c(6), lwd=1)
# lines(density(x_t_RNN),col=c(7), lwd=1)
abline(v=0,lty=2)
legend('topright',legend=c('Empirical','Normal','sged','Simple RNN','Normal RNN'),col=c(1,2,3,4,6),lwd=c(2,1,1,1,1),lty=c(1,1,1,1,1))
# legend('topright',legend=c('Real','Normal','sged','Simple RNN','Normal RNN','Student RNN'),col=c(1,2,3,4,6,7),lwd=c(2,1,1,1,1,1),lty=c(1,1,1,1,1,1))
```

```{r}
print('Empirical: mean,  std,  skew,  kurt')
cat(mean(R_pls2[1:end]),sd(R_pls2[1:end]),skewness(R_pls2[1:end]), kurtosis(R_pls2[1:end]))

print('Norm: mean,  std,  skew,  kurt')
cat(mean(x_norm),sd(x_norm),skewness(x_norm), kurtosis(x_norm))

print('Sged: mean,  std,  skew,  kurt')
cat(mean(x),sd(x),skewness(x), kurtosis(x))

print('Simp RNN: mean,  std,  skew,  kurt')
cat(mean(x_sim_RNN),sd(x_sim_RNN),skewness(x_sim_RNN), kurtosis(x_sim_RNN))

print('Normal RNN: mean,  std,  skew,  kurt')
cat(mean(x_norm_RNN),sd(x_norm_RNN),skewness(x_norm_RNN), kurtosis(x_norm_RNN))
```

```{r}
columns <- c('Real','Normal','SGED','Simple RNN','Normal RNN')
mean_all_t <- data.frame(matrix(nrow = 0, ncol=length(columns)))
colnames(mean_all_t) <- columns
sd_all_t <- data.frame(matrix(nrow = 0, ncol=length(columns)))
colnames(sd_all_t) <- columns
skew_all_t <- data.frame(matrix(nrow = 0, ncol=length(columns)))
colnames(skew_all_t) <- columns
kurt_all_t <- data.frame(matrix(nrow = 0, ncol=length(columns)))
colnames(kurt_all_t) <- columns

for(end in 100:1510){
  x_sim_RNN <- sapply(1:end,function(i) rnorm(100,mean=mu_sim_RNN[i],sd=sigma_sim_RNN[i]))
  x_sim_RNN <- c(x_sim_RNN) 
  mean_sim_RNN <- mean(x_sim_RNN)
  sd_sim_RNN <- sd(x_sim_RNN)
  skew_sim_RNN <- skewness(x_sim_RNN)
  kurt_sim_RNN <- kurtosis(x_sim_RNN)
  
  x_norm_RNN <- sapply(1:end,function(i) rnorm(100,mean=mu_norm_RNN[i],sd=sigma_norm_RNN[i]))
  x_norm_RNN <- c(x_norm_RNN) 
  mean_norm_RNN <- mean(x_norm_RNN)
  sd_norm_RNN <- sd(x_norm_RNN)
  skew_norm_RNN <- skewness(x_norm_RNN)
  kurt_norm_RNN <- kurtosis(x_norm_RNN)
  
  x_norm <- sapply(1:end,function(i) rnorm(100,mean=mu_norm[i],sd=sigma_norm[i]))
  x_norm <- c(x_norm) 
  mean_norm <- mean(x_norm)
  sd_norm <- sd(x_norm)
  skew_norm <- skewness(x_norm)
  kurt_norm <- kurtosis(x_norm)
  
  x <- sapply(1:end, function(i) rsged(100,mean=mu[i],sd=sigma[i],nu=shape,xi=skew))
  x <- c(x)
  mean_x <- mean(x)
  sd_x <- sd(x)
  skew_x <- skewness(x)
  kurt_x <- kurtosis(x)
  
  R_temp <- R_pls2[1:end]
  mean_emp <- mean(R_temp)
  sd_emp <- sd(R_temp)
  skew_emp <- skewness(R_temp)
  kurt_emp <- kurtosis(R_temp)
  
  mean_temp <- c(mean_emp,mean_norm,mean_x,mean_sim_RNN,mean_norm_RNN)
  sd_temp <- c(sd_emp,sd_norm,sd_x,sd_sim_RNN,sd_norm_RNN)
  skew_temp <- c(skew_emp,skew_norm,skew_x,skew_sim_RNN,skew_norm_RNN) 
  kurt_temp <- c(kurt_emp,kurt_norm,kurt_x,kurt_sim_RNN,kurt_norm_RNN)
  
  mean_all_t <- rbind(mean_all_t,mean_temp)
  sd_all_t <- rbind(sd_all_t,sd_temp)
  skew_all_t <- rbind(skew_all_t,skew_temp)
  kurt_all_t <- rbind(kurt_all_t,kurt_temp)
}

colnames(mean_all_t) <- columns
colnames(sd_all_t) <- columns
colnames(skew_all_t) <- columns
colnames(kurt_all_t) <- columns
```

```{r}
mse_mean_t <- (mean_all_t[,2:length(columns)]-mean_all_t$Real)^2
mse_sd_t <- (sd_all_t[,2:length(columns)]-sd_all_t$Real)^2
mse_skew_t <- (skew_all_t[,2:length(columns)]-skew_all_t$Real)^2
mse_kurt_t <- (kurt_all_t[,2:length(columns)]-kurt_all_t$Real)^2
print('L_2 difference of mean is ')
print(apply(mse_mean_t,2,mean))
print('L_2 difference of sd is ')
print(apply(mse_sd_t,2,mean))
print('L_2 difference of skewness is ')
print(apply(mse_skew_t,2,mean))
print('L_2 difference of kurtosis is ')
print(apply(mse_kurt_t,2,mean))
```

```{r}
Data_sim_RNN_test <- read.csv("~/Dropbox/Pricing/Data_R/RNN_simp_test.csv")
Data_RNN_test <- read.csv("~/Dropbox/Pricing/Data_R/RNN_test3.csv")

end_test <- 990

mu_sim_RNN_test <- Data_sim_RNN_test$mu
sigma_sim_RNN_test <- Data_sim_RNN_test$sigma
set.seed(1000)
x_sim_RNN_test <- sapply(1:end_test,function(i) rnorm(num,mean=mu_sim_RNN_test[i],sd=sigma_sim_RNN_test[i]))
x_sim_RNN_test <- c(x_sim_RNN_test) 

mu_norm_RNN_test <- Data_RNN_test$mu
sigma_norm_RNN_test <- Data_RNN_test$sigma
set.seed(1000)
x_norm_RNN_test <- sapply(1:end_test,function(i) rnorm(num,mean=mu_norm_RNN_test[i],sd=sigma_norm_RNN_test[i]))
x_norm_RNN_test <- c(x_norm_RNN_test) 

mu_norm_test <- fitted(forecast_eGARCH_pls2_norm)
sigma_norm_test <- sigma(forecast_eGARCH_pls2_norm)
set.seed(1000)
x_norm_test <- sapply(1:end_test,function(i) rnorm(num,mean=mu_norm_test[i],sd=sigma_norm_test[i]))
x_norm_test <- c(x_norm_test) 

skew <- 0.872
shape <- 1.54
mu_test <- fitted(forecast_eGARCH_pls2)
sigma_test <- sigma(forecast_eGARCH_pls2)
set.seed(1000)
x_test <- sapply(1:end_test, function(i) rsged(num,mean=mu_test[i],sd=sigma_test[i],nu=shape,xi=skew))
x_test <- c(x_test)
```

```{r}
plot(density(R_pls2[(length(R_pls2)-N_test):(length(R_pls2)-N_test+end_test)],bw=0.2), col=c(1), lwd=2, type='l',main='Distribution',xlab='Normalized R')
lines(density(x_norm_test,bw=0.2),col=c(2), lwd=1)
lines(density(x_test,bw=0.2),col=c(3), lwd=1)
lines(density(x_sim_RNN_test,bw=0.2),col=c(4), lwd=1)
lines(density(x_norm_RNN_test,bw=0.2),col=c(6), lwd=1)
# lines(density(x_t_RNN),col=c(7), lwd=1)
abline(v=0,lty=2)
legend('topright',legend=c('Empirical','Normal','sged','Simple RNN','Normal RNN'),col=c(1,2,3,4,6),lwd=c(2,1,1,1,1),lty=c(1,1,1,1,1))
```

```{r}
print('Empirical: mean,  std,  skew,  kurt')
cat(mean(R_pls2[(length(R_pls2)-N_test):(length(R_pls2)-N_test+end_test)]),sd(R_pls2[(length(R_pls2)-N_test):(length(R_pls2)-N_test+end_test)]),skewness(R_pls2[(length(R_pls2)-N_test):(length(R_pls2)-N_test+end_test)]), kurtosis(R_pls2[(length(R_pls2)-N_test):(length(R_pls2)-N_test+end_test)]))

print('Norm: mean,  std,  skew,  kurt')
cat(mean(x_norm_test),sd(x_norm_test),skewness(x_norm_test), kurtosis(x_norm_test))

print('Sged: mean,  std,  skew,  kurt')
cat(mean(x_test),sd(x_test),skewness(x_test), kurtosis(x_test))

print('Simp RNN: mean,  std,  skew,  kurt')
cat(mean(x_sim_RNN_test),sd(x_sim_RNN_test),skewness(x_sim_RNN_test), kurtosis(x_sim_RNN_test))

print('Normal RNN: mean,  std,  skew,  kurt')
cat(mean(x_norm_RNN_test),sd(x_norm_RNN_test),skewness(x_norm_RNN_test), kurtosis(x_norm_RNN_test))
```

```{r}
columns <- c('Real','Normal','SGED','Simple RNN','Normal RNN')
mean_all <- data.frame(matrix(nrow = 0, ncol=length(columns)))
colnames(mean_all) <- columns
sd_all <- data.frame(matrix(nrow = 0, ncol=length(columns)))
colnames(sd_all) <- columns
skew_all <- data.frame(matrix(nrow = 0, ncol=length(columns)))
colnames(skew_all) <- columns
kurt_all <- data.frame(matrix(nrow = 0, ncol=length(columns)))
colnames(kurt_all) <- columns

for(end_test in 100:990){
  x_sim_RNN_test <- sapply(1:end_test,function(i) rnorm(100,mean=mu_sim_RNN_test[i],sd
                                                        =sigma_sim_RNN_test[i]))
  x_sim_RNN_test <- c(x_sim_RNN_test) 
  mean_sim_RNN <- mean(x_sim_RNN_test)
  sd_sim_RNN <- sd(x_sim_RNN_test)
  skew_sim_RNN <- skewness(x_sim_RNN_test)
  kurt_sim_RNN <- kurtosis(x_sim_RNN_test)
  
  x_norm_RNN_test <- sapply(1:end_test,function(i) rnorm(100,mean=mu_norm_RNN_test[i],sd
                                                         =sigma_norm_RNN_test[i]))
  x_norm_RNN_test <- c(x_norm_RNN_test) 
  mean_norm_RNN <- mean(x_norm_RNN_test)
  sd_norm_RNN <- sd(x_norm_RNN_test)
  skew_norm_RNN <- skewness(x_norm_RNN_test)
  kurt_norm_RNN <- kurtosis(x_norm_RNN_test)
  
  x_norm_test <- sapply(1:end_test,function(i) rnorm(100,mean=mu_norm_test[i],sd
                                                     =sigma_norm_test[i]))
  x_norm_test <- c(x_norm_test) 
  mean_norm <- mean(x_norm_test)
  sd_norm <- sd(x_norm_test)
  skew_norm <- skewness(x_norm_test)
  kurt_norm <- kurtosis(x_norm_test)
  
  x_test <- sapply(1:end_test, function(i) rsged(100,mean=mu_test[i],sd=sigma_test[i],nu=shape
                                                 ,xi=skew))
  x_test <- c(x_test)
  mean_x <- mean(x_test)
  sd_x <- sd(x_test)
  skew_x <- skewness(x_test)
  kurt_x <- kurtosis(x_test)
  
  R_temp <- R_pls2[(length(R_pls2)-N_test):(length(R_pls2)-N_test+end_test)]
  mean_emp <- mean(R_temp)
  sd_emp <- sd(R_temp)
  skew_emp <- skewness(R_temp)
  kurt_emp <- kurtosis(R_temp)
  
  mean_temp <- c(mean_emp,mean_norm,mean_x,mean_sim_RNN,mean_norm_RNN)
  sd_temp <- c(sd_emp,sd_norm,sd_x,sd_sim_RNN,sd_norm_RNN)
  skew_temp <- c(skew_emp,skew_norm,skew_x,skew_sim_RNN,skew_norm_RNN) 
  kurt_temp <- c(kurt_emp,kurt_norm,kurt_x,kurt_sim_RNN,kurt_norm_RNN)
  
  mean_all <- rbind(mean_all,mean_temp)
  sd_all <- rbind(sd_all,sd_temp)
  skew_all <- rbind(skew_all,skew_temp)
  kurt_all <- rbind(kurt_all,kurt_temp)
}

colnames(mean_all) <- columns
colnames(sd_all) <- columns
colnames(skew_all) <- columns
colnames(kurt_all) <- columns
```

```{r}
print('Mean')
print(mean_all[nrow(mean_all),])
print('sd')
print(sd_all[nrow(mean_all),])
print('skew')
print(skew_all[nrow(mean_all),])
print('kurt')
print(kurt_all[nrow(mean_all),])
```

```{r}
mse_mean <- (mean_all[,2:length(columns)]-mean_all$Real)^2
mse_sd <- (sd_all[,2:length(columns)]-sd_all$Real)^2
mse_skew <- (skew_all[,2:length(columns)]-skew_all$Real)^2
mse_kurt <- (kurt_all[,2:length(columns)]-kurt_all$Real)^2
print('L_2 difference of mean is ')
print(apply(mse_mean,2,mean))
print('L_2 difference of sd is ')
print(apply(mse_sd,2,mean))
print('L_2 difference of skewness is ')
print(apply(mse_skew,2,mean))
print('L_2 difference of kurtosis is ')
print(apply(mse_kurt,2,mean))
```

### DCC VAR for PLS factors

From ACF and PACF, for PLS factors from \$R\$, each series follows AR(2). For factors from $R^2$, except factor 3, they follow AR(2) as well.

```{r}
library(vars)
library(rmgarch)
library(MTS)

# Plot ACF and PACF for factors
V_norm_lag <- V_norm[(lags+1):nrow(V_norm),]
for(i in 1:ncol(V_norm)){
  Acf(V_norm_lag[,i])
  Pacf(V_norm_lag[,i])
}
```

```{r}
V_norm2_lag <- V_norm2[(lags+1):nrow(V_norm),]
for(i in 1:ncol(V_norm2)){
  Acf(V_norm2_lag[,i])
  Pacf(V_norm2_lag[,i])
}
```

From VARselect, we conclude that the optimal lag for VAR model is 2 for both factors from $R$ and $R^2$.

```{r}
# Select optimal AR lag for factors from R
VARselect(V_norm_lag,lag.max=10,type="none")
```

```{r}
# Select optimal AR lag for factors from R^2
VARselect(V_norm2_lag,lag.max=10,type="none")
```

However, the residuals of VAR(2) model do not pass the ARCH-LM test, so they have heteroscedasticity.

```{r}
# VAR model for R
V_norm_lag1 <- data.frame(V_norm_lag)
V_norm_lag1 <- rev(V_norm_lag1)
V_norm_lag1 <- as.matrix(V_norm_lag1)
VAR_pls <- vars::VAR(V_norm_lag1,p=1,type="none")
summary(VAR_pls)
```

```{r}
# Residual check
arch.test(VAR_pls)
```

```{r}
# VAR model for R^2
V_norm2_lag1 <- data.frame(V_norm2_lag)
V_norm2_lag1 <- rev(V_norm2_lag1)
V_norm2_lag1 <- as.matrix(V_norm2_lag1)
VAR_pls2 <- vars::VAR(V_norm2_lag1,p=1,type="none")
summary(VAR_pls2)
```

```{r}
# Residual check
arch.test(VAR_pls2)
```

The optimal model for factors from both $R$ and $R^2$ is DCC(1,1)+VAR(2). It passes the ARCH-LM test and Ljung-Box test for residuals.

```{r}
# Model for R
xspec_pls_1 <- ugarchspec(mean.model = list(armaOrder = c(0, 0),include.mean=TRUE), variance.model = list(garchOrder = c(1,1), model = 'eGARCH'), distribution.model = 'sstd')
xspec_pls_2 <- ugarchspec(mean.model = list(armaOrder = c(0, 0),include.mean=TRUE), variance.model = list(garchOrder = c(1,1), model = 'eGARCH'), distribution.model = 'sstd')
xspec_pls_3 <- ugarchspec(mean.model = list(armaOrder = c(0, 0),include.mean=TRUE), variance.model = list(garchOrder = c(1,1), model = 'eGARCH'), distribution.model = 'sstd')
uspec_pls <- multispec(c(xspec_pls_1, xspec_pls_2, xspec_pls_3))
spec1_pls <- dccspec(uspec = uspec_pls, VAR=TRUE, robust=TRUE,lag=1, dccOrder = c(1,1), model="DCC", distribution = 'mvt')
fit_pls <- dccfit(spec1_pls, data = V_norm_lag1, fit.control = list(eval.se = TRUE), out.sample=N_test-1)
fit_pls
fit_pls@model$varcoef
```

```{r}
# In-sample
print('In-sample MSEs are')
apply(fit_pls@model$residuals^2,2,mean)
```

```{r}
forcast_dcc_pls <- dccforecast(fit_pls,n.ahead=1,n.roll=N_test-1)
fitted_pls <- t(fitted(forcast_dcc_pls)[1,,])
sigma_pls <- t(sigma(forcast_dcc_pls)[1,,])
mse_pls_temp <- (fitted_pls-V_norm_lag1[(nrow(V_norm_lag1)-N_test+1):nrow(V_norm_lag1),])^2
print('MSEs are')
apply(mse_pls_temp,2,mean)
print('Means of sd are')
apply(sigma_pls,2,mean)
```

```{r}
# 95% CI
for(i in 1:ncol(V_norm_lag1)){
  plot(V_norm_lag1[(nrow(V_norm_lag1)-N_test+1):(nrow(V_norm_lag1)-N_test+100),i],type='l',xlab='Date',ylab='Return',main="Out-of-sample")
  lines(fitted_pls[1:100,i],col='blue')
  # lines(fitted_pls2[,i]+1.96*sigma_pls2[,i],col='green')
  # lines(fitted_pls2[,i]-1.96*sigma_pls2[,i],col='green')
}
```

```{r}
# Multivariate Ljung Box test for residuals
res_pls <- fit_pls@mfit$stdresid
mq(res_pls,lag=10,adj=2)
```

```{r}
# Multi-variate ARCH LM test for residuals
MarchTest(res_pls,lag=10)
```

```{r}
# Model for R^2
xspec_pls_1 <- ugarchspec(mean.model = list(armaOrder = c(0, 0),include.mean=TRUE),variance.model = list(garchOrder = c(1,1), model = 'eGARCH'), distribution.model = 'snorm')
xspec_pls_2 <- ugarchspec(mean.model = list(armaOrder = c(0, 0),include.mean=TRUE),variance.model = list(garchOrder = c(1,1), model = 'eGARCH'), distribution.model = 'sstd')
xspec_pls_3 <- ugarchspec(mean.model = list(armaOrder = c(0, 0),include.mean=TRUE),variance.model = list(garchOrder = c(1,1), model = 'eGARCH'), distribution.model = 'sstd')
xspec_pls_4 <- ugarchspec(mean.model = list(armaOrder = c(0, 0),include.mean=TRUE), variance.model = list(garchOrder = c(1,1), model = 'eGARCH'), distribution.model = 'sstd')
xspec_pls_5 <- ugarchspec(mean.model = list(armaOrder = c(0, 0),include.mean=TRUE), variance.model = list(garchOrder = c(1,1), model = 'eGARCH'), distribution.model = 'sstd')
uspec_pls2 <- multispec(c(xspec_pls_1, xspec_pls_2, xspec_pls_3,xspec_pls_4,xspec_pls_5))
spec1_pls2 <- dccspec(uspec = uspec_pls2, VAR=TRUE, robust=TRUE,lag=1, dccOrder = c(1,1), model="DCC", distribution = 'mvt')
fit_pls2 <- dccfit(spec1_pls2, data = V_norm2_lag, fit.control = list(eval.se = TRUE), out.sample=N_test-1)
fit_pls2
fit_pls2@model$varcoef
```

```{r}
# In-sample
print('In-sample MSEs are')
apply(fit_pls2@model$residuals^2,2,mean)
```

```{r}
# Out-of-sample
forcast_dcc_pls2 <- dccforecast(fit_pls2,n.ahead=1,n.roll=N_test-1)
fitted_pls2 <- t(fitted(forcast_dcc_pls2)[1,,])
sigma_pls2 <- t(sigma(forcast_dcc_pls2)[1,,])
mse_pls_temp2 <- (fitted_pls2-V_norm2_lag[(nrow(V_norm2_lag)-N_test+1):nrow(V_norm2_lag),])^2
print('MSEs are')
apply(mse_pls_temp2,2,mean)
print('Means of sd are')
apply(sigma_pls2,2,mean)
```

```{r}
# 95% CI
for(i in 1:ncol(V_norm2_lag)){
  plot(V_norm2_lag[(nrow(V_norm2_lag)-N_test+1):(nrow(V_norm2_lag)-N_test+100),i],type='l',xlab='Date',ylab='Return',main="Out-of-sample")
  lines(fitted_pls2[1:100,i],col='blue')
  # lines(fitted_pls2[,i]+1.96*sigma_pls2[,i],col='green')
  # lines(fitted_pls2[,i]-1.96*sigma_pls2[,i],col='green')
}


```

```{r}
# Multivariate Ljung Box test for residuals
res_pls2 <- fit_pls2@mfit$stdresid
mq(res_pls2,lag=10,adj=2)
```

```{r}
# Multi-variate ARCH LM test for residuals
MarchTest(res_pls2,lag=10)
```

### 10-step ahead prediction

```{r}
# library(abind)
# 
# Transto2d <- function(x){
#   result <- array(numeric(),c(0,dim(x)[2]))
#   for(i in 1:dim(x)[3]){
#     result <- rbind(result,x[,,i])
#   }
#   return(result)
# }
# 
# N_step_ahead <- 10
# Num_train <- nrow(V_norm_lag)-N_test
# 
# V_norm2_train <- V_norm2_lag[1:(nrow(V_norm_lag)-N_test),]
# V_norm_train <- V_norm_lag[1:(nrow(V_norm_lag)-N_test),]
# 
# refit_window <- 252
# Num_iter <- ceiling(N_test/refit_window)
# x1 <- array(numeric(),c(N_step_ahead,ncol(V_norm_lag),0))
# x2 <- array(numeric(),c(N_step_ahead,ncol(V_norm2_lag),0))
# for(i in 1:Num_iter){
#   start <- nrow(V_norm_lag)-N_test+(i-1)*refit_window+1
#   end <- min(nrow(V_norm_lag)-N_step_ahead+1,nrow(V_norm_lag)-N_test+i*refit_window)
#   x1_temp <- array(numeric(),c(0,ncol(V_norm_lag),(end-start+1)))
#   x2_temp <- array(numeric(),c(0,ncol(V_norm2_lag),(end-start+1)))
#   
#   V_norm2_train_temp <- V_norm2_lag[1:(start-1),]
#   V_norm_train_temp <- V_norm_lag[1:(start-1),]
#   V_norm2_test_temp <- V_norm2_lag[start:end,]
#   V_norm_test_temp <- V_norm_lag[start:end,]
#   
#   V_norm2_temp <- rbind(V_norm2_train_temp,V_norm2_test_temp)
#   V_norm_temp <- rbind(V_norm_train_temp,V_norm_test_temp)
#   
#   fit_pls2_temp <- dccfit(spec1_pls2, data = V_norm2_temp, fit.control = list(eval.se = TRUE),
#                           out.sample=(end-start))
#   forecast_dcc_pls2_temp <- dccforecast(fit_pls2_temp,n.ahead=1,n.roll=(end-start))
#   fitted_pls2_temp <- fitted(forecast_dcc_pls2_temp)[1,,]
#   
#   fit_pls_temp <- dccfit(spec1_pls, data = V_norm_temp, fit.control = list(eval.se = TRUE),
#                           out.sample=(end-start))
#   forecast_dcc_pls1_temp <- dccforecast(fit_pls_temp,n.ahead=1,n.roll=(end-start))
#   fitted_pls1_temp <- fitted(forecast_dcc_pls1_temp)[1,,]
#   
#   x1_temp <- abind(x1_temp,fitted_pls1_temp[,1:(end-start+1)],along=1)
#   x2_temp <- abind(x2_temp,fitted_pls2_temp[,1:(end-start+1)],along=1)
#   
#   seq_mark <- seq(from=4,to=3*(end-start+1)+1,by=3)
#   for(l in 2:N_step_ahead){
#     V_norm2_test_temp <- array(numeric(),c(0,ncol(V_norm2_lag),(end-start+1)))
#     V_norm_test_temp <- array(numeric(),c(0,ncol(V_norm_lag),(end-start+1)))
#     
#     if(l==2){
#       V_norm2_test_temp <- abind(V_norm2_test_temp,t(V_norm2_lag[(start-1):(end-1),]),along=1)
#       V_norm_test_temp <- abind(V_norm_test_temp,t(V_norm_lag[(start-1):(end-1),]),along=1)
#     }else{
#       V_norm2_test_temp <- abind(V_norm2_test_temp,x2_temp[l-2,,],along=1)
#       V_norm_test_temp <- abind(V_norm_test_temp,x1_temp[l-2,,],along=1)
#     }
#     V_norm2_test_temp <- abind(V_norm2_test_temp,x2_temp[l-1,,],along=1)
#     V_norm_test_temp <- abind(V_norm_test_temp,x1_temp[l-1,,],along=1)
#     V_norm2_test_temp <- abind(V_norm2_test_temp,t(V_norm2_lag[(start+l-1):(end+l-1),]),
#                                along=1)
#     V_norm_test_temp <- abind(V_norm_test_temp,t(V_norm_lag[(start+l-1):(end+l-1),]),along=1)
#     
#     V_norm2_test_temp <- Transto2d(V_norm2_test_temp)
#     V_norm_test_temp <- Transto2d(V_norm_test_temp)
#     
#     V_norm2_temp <- rbind(V_norm2_train_temp,V_norm2_test_temp)
#     V_norm_temp <- rbind(V_norm_train_temp,V_norm_test_temp)
#   
#     fit_pls2_temp <- dccfit(spec1_pls2, data = V_norm2_temp, fit.control = 
#                               list(eval.se = TRUE),out.sample=3*(end-start+1))
#     forecast_dcc_pls2_temp <- dccforecast(fit_pls2_temp,n.ahead=1,n.roll=3*(end-start+1))
#     fitted_pls2_temp <- fitted(forecast_dcc_pls2_temp)[1,,]
#   
#     fit_pls_temp <- dccfit(spec1_pls, data = V_norm_temp, fit.control = list(eval.se = TRUE),
#                           out.sample=3*(end-start+1))
#     forecast_dcc_pls1_temp <- dccforecast(fit_pls_temp,n.ahead=1,n.roll=3*(end-start+1))
#     fitted_pls1_temp <- fitted(forecast_dcc_pls1_temp)[1,,]
#     
#     fitted_pls2_temp <- fitted_pls2_temp[,seq_mark]
#     fitted_pls1_temp <- fitted_pls1_temp[,seq_mark]
#     
#     x1_temp <- abind(x1_temp,fitted_pls1_temp,along=1)
#     x2_temp <- abind(x2_temp,fitted_pls2_temp,along=1)
#   }
#   x1 <- abind(x1,x1_temp,along=3)
#   x2 <- abind(x2,x2_temp,along=3)
# }


```

```{r}
library(abind)

MultipleCoef <- function(coef,x,N_step){
  coef_const <- t(t(coef[,'const']))
  coef_x <- coef[,1:(ncol(coef)-1)]
  x1 <- x
  
  result <- array(numeric(),c(0,dim(x)[1],dim(x)[2]))
  for(i in 1:N_step){
    x1 <- matrix(rep(coef_const,dim(x)[2]),ncol=dim(x)[2]) + coef_x%*%x1
    result <- abind(result,x1,along=1)
  }
  return(result)
}

N_step_ahead <- 10
Num_train <- nrow(V_norm_lag)-N_test

refit_window <- 252
Num_iter <- ceiling(N_test/refit_window)

x1 <- array(numeric(),c(N_step_ahead,ncol(V_norm_lag),0))
x2 <- array(numeric(),c(N_step_ahead,ncol(V_norm2_lag),0))
for(i in 1:Num_iter){
  start <- nrow(V_norm_lag)-N_test+(i-1)*refit_window+1
  end <- min(nrow(V_norm_lag)-N_step_ahead+1,nrow(V_norm_lag)-N_test+i*refit_window)
  
  V_norm2_train_temp <- V_norm2_lag[1:(start-1),]
  V_norm_train_temp <- V_norm_lag1[1:(start-1),]
  V_norm2_test_temp <- V_norm2_lag[start:end,]
  V_norm_test_temp <- V_norm_lag1[start:end,]
  
  V_norm2_temp <- rbind(V_norm2_train_temp,V_norm2_test_temp)
  V_norm_temp <- rbind(V_norm_train_temp,V_norm_test_temp)
  
  fit_pls2_temp <- dccfit(spec1_pls2, data = V_norm2_temp, fit.control = list(eval.se = TRUE),
                          out.sample=(end-start))
  forcast_dcc_pls2_temp <- dccforecast(fit_pls2_temp,n.ahead=1,n.roll=(end-start))
  fitted_pls2_temp <- fitted(forcast_dcc_pls2_temp)[1,,]
  
  
  VAR2_coef <- fit_pls2_temp@model$varcoef
  fit_pls_temp <- dccfit(spec1_pls, data = V_norm_temp, fit.control = list(eval.se = TRUE),
                          out.sample=(end-start))
  forcast_dcc_pls1_temp <- dccforecast(fit_pls_temp,n.ahead=1,n.roll=(end-start))
  fitted_pls1_temp <- fitted(forcast_dcc_pls1_temp)[1,,]
  VAR_coef <- fit_pls_temp@model$varcoef
  
  x2_temp <- MultipleCoef(VAR2_coef,fitted_pls2_temp,N_step_ahead-1)
  x1_temp <- MultipleCoef(VAR_coef,fitted_pls1_temp,N_step_ahead-1)
  x2_temp <- abind(fitted_pls2_temp,x2_temp,along=1)
  x1_temp <- abind(fitted_pls1_temp,x1_temp,along=1)
  x2 <- abind(x2,x2_temp,along=3)
  x1 <- abind(x1,x1_temp,along=3)
}
x1 <- x1[,ncol(x1):1,]
```

```{r}
saveRDS(x1, file = "~/Dropbox/Pricing/Data_R/x1.rds")
saveRDS(x2, file = "~/Dropbox/Pricing/Data_R/x2.rds")
```

```{r}
Num_iter_R <- ceiling((N_test-N_step_ahead+1)/refit_window)
Num_train_R <- length(R_pls2)-N_test

mean_std_extract <- function(j,R_pls2,V_norm_lag,V_norm2_lag,x1,x2){
  R_pls2_temp <- R_pls2[1:(j+N_step_ahead-1)]
  V_norm_temp <- rbind(V_norm_lag[1:(j-1),],x1[,,(j-start+1)])
  V_norm_temp_lag1 <- rbind(V_norm[2:(j+1),],x1[1:(N_step_ahead-1),,(j-start+1)])
  V_norm_temp_lag2 <- rbind(V_norm[1:(j+1),],x1[1:(N_step_ahead-2),,(j-start+1)])
  V_norm_temp <- cbind(V_norm_temp,V_norm_temp_lag1,V_norm_temp_lag2)
    
  V_norm2_temp <- rbind(V_norm2_lag[1:(j-1),],x2[,,(j-start+1)])
    
  spec.eGARCH_pls2_temp <- ugarchspec(variance.model=list(model="eGARCH",
                    garchOrder=c(1,1),external.regressors = as.matrix(V_norm2_temp)), 
                    mean.model=list(armaOrder = c(1,1),include.mean=FALSE,external.regressors =
                                      as.matrix(V_norm_temp)), distribution.model="sged")
  eGARCH_pls2_temp <- ugarchfit(R_pls2_temp, spec=spec.eGARCH_pls2_temp,
                                  out.sample=j+N_step_ahead-1-start)
  forecast_eGARCH_pls2_temp <- ugarchforecast(eGARCH_pls2_temp, data = R_pls2_temp, 
                                                n.ahead = N_step_ahead, 
                                                n.roll = j+N_step_ahead-1-start,
                                                out.sample =j+N_step_ahead-1-start)
  fitted_eGARCH_pls2_temp <- fitted(forecast_eGARCH_pls2_temp)
  sigma_eGARCH_pls2_temp <- sigma(forecast_eGARCH_pls2_temp)
  
  fitted <- t(t(fitted_eGARCH_pls2_temp[,ncol(fitted_eGARCH_pls2_temp)-N_step_ahead+1]))
  sigma <- t(t(sigma_eGARCH_pls2_temp[,ncol(sigma_eGARCH_pls2_temp)-N_step_ahead+1]))
  skew_shape <- t(t(eGARCH_pls2_temp@fit$coef[c('skew','shape')]))
  
  result <- list('fit'=fitted,'sigma'=sigma,'skew_shape'=skew_shape)
  return(result)
}

mean_N_step <- c()
std_N_step <- c()
skew_shape <- c()
for(i in 1:Num_iter_R){
  start <- Num_train_R + (i-1)*refit_window + 1
  end <-  min(length(R_pls2)-N_step_ahead+1,Num_train_R+i*refit_window)
  
  mylist <- sapply(start:end,function(x) mean_std_extract(x,R_pls2,V_norm_lag,
                                                          V_norm2_lag,x1,x2))
  
  for(j in 1:(end-start+1)){
    mean_N_step <- cbind(mean_N_step,mylist[,j]$fit)
    std_N_step <- cbind(std_N_step,mylist[,j]$sigma)
    skew_shape <- cbind(skew_shape,mylist[,j]$skew_shape)
  }
}


```

```{r}
saveRDS(mean_N_step, file = "~/Dropbox/Pricing/Data_R/mean_N_step.rds")
saveRDS(std_N_step, file = "~/Dropbox/Pricing/Data_R/std_N_step.rds")
saveRDS(skew_shape, file = "~/Dropbox/Pricing/Data_R/skew_shape.rds")
```

```{r}
R_pls2_N_step <- R_pls2[(length(R_pls2)-ncol(mean_N_step)+1):length((R_pls2))]
mean_N <- mean_N_step[dim(mean_N_step)[1],]
std_N <- std_N_step[dim(std_N_step)[1],]
skew_N <- skew_shape['skew',]
nu_N <- skew_shape['shape',]
quantile <- 0.9
VaR_N_step <- t(t(qsged(1-quantile,mean_N,std_N,nu_N,skew_N)))

count_N_step <- (R_pls2_N_step<VaR_N_step)
print(sum(count_N_step))
print(sum(count_N_step)/length(R_pls2_N_step))
```

```{r}
quantile <- 0.95
VaR_N_step <- t(t(qsged(1-quantile,mean_N,std_N,nu_N,skew_N)))

count_N_step <- (R_pls2_N_step<VaR_N_step)
print(sum(count_N_step))
print(sum(count_N_step)/length(R_pls2_N_step))
```

```{r}
quantile <- 0.99
VaR_N_step <- t(t(qsged(1-quantile,mean_N,std_N,nu_N,skew_N)))

count_N_step <- (R_pls2_N_step<VaR_N_step)
print(sum(count_N_step))
print(sum(count_N_step)/length(R_pls2_N_step))
```

```{r}
mean((R_pls2_N_step-mean_N)^2*sd(R_train)^2)
```

## Cohen's factors

```{r}
rm(list=ls())
library(rugarch)
library(car)
library(tseries)
library(Dowd)
library(seastests)
library(vars)

# import data
Data_co <- read.csv("/Users/benjye/Dropbox/Pricing/Data_R/Data_co.csv",header=TRUE)
X_co <- Data_co[,2:3]
S <- Data_co[,4]
R <- diff(log(S))
S <- S[-length(S)]
X_co <- X_co[-nrow(X_co),]
```

The factors are both stationary,

```{r}
# ADF test for factors
adf.test(X_co[,1],k=10)
adf.test(X_co[,2],k=10)
```

```{r}
# Normalize data
N_test <- 1000
start <- 1767
S_train <- S[start:(length(S)-N_test)]
S_test <- S[(length(S)-N_test+1):length(S)]
R_train <- R[start:(length(R)-N_test)]
R_test <- R[(length(R)-N_test+1):length(R)]
X_co_train <- X_co[start:(nrow(X_co)-N_test),]
X_co_test <- X_co[(nrow(X_co)-N_test+1):nrow(X_co),]

S_train_norm <- (S_train-mean(S_train))/sd(S_train)
S_test_norm <- (S_test-mean(S_train))/sd(S_train)
R_train_norm <- (R_train-mean(R_train))/sd(R_train)
R_test_norm <- (R_test-mean(R_train))/sd(R_train)
X_co_train_1 <- (X_co_train[,1]-mean(X_co_train[,1]))/sd(X_co_train[,1])
X_co_test_1 <- (X_co_test[,1]-mean(X_co_train[,1]))/sd(X_co_train[,1])
X_co_train_2 <- (X_co_train[,2]-mean(X_co_train[,2]))/sd(X_co_train[,2])
X_co_test_2 <- (X_co_test[,2]-mean(X_co_train[,2]))/sd(X_co_train[,2])
```

```{r}
# Plot R vs X_co
plot(X_co_train_1,R_train_norm,main='R vs X_1')
lm_2 <- lm(R_train_norm~poly(X_co_train_1,2))
abline(lm_2,col='blue')
plot(X_co_train_2,R_train_norm,main='R vs X_2')
lm_3 <- lm(R_train_norm~poly(X_co_train_2,2))
abline(lm_3,col='blue')
```

The estimation is better in the test data since it has less abnormal data points.

```{r}
plot(R[1:(length(R)-N_test)],type='l',xlab='Date',ylab='R_t',main='Training data')
plot(R[(length(R)-N_test+1):length(R)],type='l',xlab='Date',ylab='R_t',main='Test data')
```

We first try the standard GARCH model on the data. However, it does not eliminate the autocorrelation in the residuals and the residuals are not normal. However, it does not pass the coverage test.

```{r}
# sGARCH model
X_train <- cbind(X_co_train_1,X_co_train_2)
X_test <- cbind(X_co_test_1,X_co_test_2)
X_all <- rbind(X_train,X_test)
R_all <- c(R_train_norm,R_test_norm)
S_all <- c(S_train_norm,S_test_norm)

spec.GARCH_sim <- ugarchspec(variance.model=list(model="sGARCH", 
                garchOrder=c(0,1)), mean.model=list(armaOrder = c(0,0),include.mean=FALSE), 
                distribution.model="norm")
GARCH_sim <- ugarchfit(R_all, spec=spec.GARCH_sim,out.sample = N_test)
GARCH_sim
```

```{r}
# In-sample MSE
sprintf('In-sample MSE is %g',mean((GARCH_sim@fit$fitted.values*sd(R_train)+mean(R_train)-R_train)^2))
```

```{r}
forecast_sim<-ugarchforecast(GARCH_sim, data = R, n.ahead = 1, n.roll = N_test,out.sample =N_test)
sigma_sim<-sigma(forecast_sim)
fitted_sim<-fitted(forecast_sim)
sprintf('Out-of-sample MSE is %g',mean((forecast_sim@forecast$seriesFor*sd(R_train)+mean(R_train)-R[(length(R)-N_test):length(R)])^2))
```

```{r}
plot(R[(length(R)-N_test):length(R)],type='l')
lines(t(fitted_sim)*sd(R_train)+mean(R_train),col='blue')
lines(t(fitted_sim)*sd(R_train)+mean(R_train)+1.96*t(sigma_sim)*sd(R_train),col='green')
lines(t(fitted_sim)*sd(R_train)+mean(R_train)-1.96*t(sigma_sim)*sd(R_train),col='green')
```

```{r}
# Coverage test
roll_sim<-ugarchroll(spec=spec.GARCH_sim, data=R, n.ahead=1, forecast.length=N_test, refit.every=253, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.05, keep.coef=TRUE)
report(roll_sim, type="VaR", VaR.alpha = 0.05, conf.level = 0.95) 
```

```{r}
# Residual check
Box.test(GARCH_sim@fit$residuals^2, lag = 10, type = "Ljung")
jarque.bera.test(GARCH_sim@fit$residuals)
```

Next, we add the latent factors to the model. In-sample MSE is 0.0001855, while out-of-sample MSE is 0.0001367. However, the residuals are not normal and are heteroscedastic. It passes the coverage test.

```{r}
lags <- 0
N_train <- nrow(X_all)
X_co_1_all <- X_all[(lags+1):N_train,1]
X_co_2_all <- X_all[(lags+1):N_train,2]
for(i in 1:lags){
  if(lags==0){
    break
  }else{
    temp_1 <- X_all[(lags+1-i):(N_train-i),1]
    temp_2 <- X_all[(lags+1-i):(N_train-i),2]
  
    X_co_1_all <- cbind(X_co_1_all,temp_1)
    X_co_2_all <- cbind(X_co_2_all,temp_2)
  }
}


R_co <- R_all[(lags+1):N_train]
X_train_new <- cbind(as.matrix(X_co_1_all),as.matrix(X_co_2_all))

# gjrGARCH
spec.GARCH_1 <- ugarchspec(variance.model=list(model="sGARCH", 
                            garchOrder=c(1,1),external.regressors = as.matrix(X_train_new)), 
                            mean.model=list(armaOrder = c(0,0),include.mean=TRUE,
                                            external.regressors = as.matrix(X_train_new)), 
                            distribution.model="norm")
sGARCH <- ugarchfit(R_co, spec=spec.GARCH_1,out.sample=N_test)
sGARCH
```

```{r}
# In-sample
sprintf('In-sample MSE is %g',mean((sGARCH@fit$residuals*sd(R_train))^2))
```

```{r}
# Out-of-sample
forecast_GARCH1<-ugarchforecast(sGARCH, data = R_co, n.ahead = 1, n.roll = N_test,out.sample =N_test)
sigma_GARCH1<-sigma(forecast_GARCH1)
fitted_GARCH1<-fitted(forecast_GARCH1)

sprintf('Out-of-sample MSE is %g',mean((t(fitted_GARCH1)*sd(R_train)+mean(R_train)-R[(length(R)-N_test):length(R)])^2))
sprintf('Out-of-sample mean of sd is %g',mean(sigma_GARCH1))
```

```{r}
plot(R[(length(R)-N_test):length(R)],type='l')
lines(t(fitted_GARCH1)*sd(R_train)+mean(R_train),col='blue')
lines(t(fitted_GARCH1)*sd(R_train)+mean(R_train)+1.96*t(sigma_GARCH1)*sd(R_train),col='green')
lines(t(fitted_GARCH1)*sd(R_train)+mean(R_train)-1.96*t(sigma_GARCH1)*sd(R_train),col='green')
```

```{r}
# Residual check
qqnorm(sGARCH@fit$residuals)
qqline(sGARCH@fit$residuals,lwd = 2)
jarque.bera.test(sGARCH@fit$residuals)
Box.test(sGARCH@fit$residuals, lag = 10, type = "Ljung")
Box.test(sGARCH@fit$residuals^2, lag = 10, type = "Ljung")
```

```{r}
# Coverage test
roll_GARCH<-ugarchroll(spec=spec.GARCH_1, data=R_co, n.ahead=1, forecast.length=N_test, refit.every=253, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.05, keep.coef=TRUE)
report(roll_GARCH, type="VaR", VaR.alpha = 0.05, conf.level = 0.95) 
```

Finally, we add lags into the model. In-sample MSE is 0.0001842, while the out-of-sample MSE is 0.0001291. It passes the coverage test.

```{r}
# Create external regressor with lags
lags <- 1
N_train <- nrow(X_all)
X_co_1_all <- X_all[(lags+1):N_train,1]
X_co_2_all <- X_all[(lags+1):N_train,2]
for(i in 1:lags){
  if(lags==0){
    break
  }else{
    temp_1 <- X_all[(lags+1-i):(N_train-i),1]
    temp_2 <- X_all[(lags+1-i):(N_train-i),2]
  
    X_co_1_all <- cbind(X_co_1_all,temp_1)
    X_co_2_all <- cbind(X_co_2_all,temp_2)
  }
}


R_co <- R_all[(lags+1):N_train]
X_train_new <- cbind(as.matrix(X_co_1_all),as.matrix(X_co_2_all))

# eGARCH
spec.gjrGARCH <- ugarchspec(variance.model=list(model="eGARCH", 
                            garchOrder=c(2,2),external.regressors = as.matrix(X_train_new)), 
                            mean.model=list(armaOrder = c(1,1),include.mean=FALSE,
                                            external.regressors = as.matrix(X_train_new)), 
                            distribution.model="std")
gjrGARCH <- ugarchfit(R_co, spec=spec.gjrGARCH,out.sample=N_test)
gjrGARCH
```

```{r}
# In-sample mse
sprintf('In-sample MSE is %g',mean((gjrGARCH@fit$residuals*sd(R_train))^2))
```

```{r}
# Out-of-sample
forecast_gjrGARCH<-ugarchforecast(gjrGARCH, data = R_co, n.ahead = 1, n.roll = N_test,out.sample =N_test)
sigma_gjrGARCH<-sigma(forecast_gjrGARCH)
fitted_gjrGARCH<-fitted(forecast_gjrGARCH)
sprintf('Out-of-sample MSE is %g',mean(((t(fitted_gjrGARCH)-R_co[(length(R_co)-N_test):length(R_co)])*sd(R_train))^2))
sprintf('Out-of-sample mean of sd is %g',mean(sigma_gjrGARCH))
```

```{r}
plot(R[(length(R)-N_test):length(R)],type='l')
lines(t(fitted_gjrGARCH)*sd(R_train)+mean(R_train),col='blue')
lines(t(fitted_gjrGARCH)*sd(R_train)+mean(R_train)+1.96*t(sigma_gjrGARCH)*sd(R_train),col='green')
lines(t(fitted_gjrGARCH)*sd(R_train)+mean(R_train)-1.96*t(sigma_gjrGARCH)*sd(R_train),col='green')
```

```{r}
# Residual check
TQQPlot(gjrGARCH@fit$residuals, 9)
Box.test(gjrGARCH@fit$residuals, lag = 10, type = "Ljung")
Box.test(gjrGARCH@fit$residuals^2, lag = 10, type = "Ljung")
```

```{r}
# Coverage test
roll_GARCH<-ugarchroll(spec=spec.gjrGARCH, data=R_co, n.ahead=1, forecast.length=N_test, refit.every=253, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.05, keep.coef=TRUE)
report(roll_GARCH, type="VaR", VaR.alpha = 0.05, conf.level = 0.95) 
```

### DCC VAR for factors

The optimal number of VAR components is 4 by VARselect.

```{r}
library(rmgarch)
library(MTS)

# ACF and PACF for factors
for(i in 1:2){
  Acf(X_all[,i])
  Pacf(X_all[,i])
}
```

```{r}
VARselect(X_all,lag.max=10,type="none")
```

However, if we use VAR(4), its residuals does not pass the ARCH-LM test.

```{r}
VAR_co <- vars::VAR(X_co,p=4,type="none")
summary(VAR_co)
```

```{r}
# heteroscedasticity test
arch.test(VAR_co)
```

The best model is DCC(2,2)+VAR(4). The residuals pass the Ljung-Box and ARCH-LM test.

```{r}
xspec_co_1 <- ugarchspec(mean.model = list(armaOrder = c(4, 0),include.mean=TRUE), variance.model = list(garchOrder = c(1,1), model = 'eGARCH'), distribution.model = 'std')
xspec_co_2 <- ugarchspec(mean.model = list(armaOrder = c(4, 0),include.mean=TRUE), variance.model = list(garchOrder = c(1,1), model = 'eGARCH'), distribution.model = 'std')
uspec_co <- multispec(c(xspec_co_1, xspec_co_2))
spec1_co <- dccspec(uspec = uspec_co, VAR=TRUE, robust=TRUE,lag=4, dccOrder = c(2,2), model="DCC", distribution = 'mvt')
fit_co <- dccfit(spec1_co, data = X_all, fit.control = list(eval.se = TRUE), out.sample=N_test)
fit_co
fit_co@model$varcoef
```

```{r}
# In-sample
print('In-sample MSEs are')
apply(fit_co@model$residuals^2,2,mean)
```

```{r}
# out-of-sample mse and mean of sd
forcast_dcc_co <- dccforecast(fit_co,n.ahead=1,n.roll=N_test)
fitted_co <- t(fitted(forcast_dcc_co)[1,,])
sigma_co <- t(sigma(forcast_dcc_co)[1,,])
mse_co_temp <- (fitted_co-X_co[(nrow(X_co)-N_test):nrow(X_co),])^2
print('MSEs are')
apply(mse_co_temp,2,mean)
print('Means of sd are')
apply(sigma_co,2,mean)
```

```{r}
# Ljung-Box test
res_co <- fit_co@mfit$stdresid
mq(res_co,lag=10,adj=4)
```

```{r}
# ARCH-LM test
MarchTest(res_co,lag=10)
```

## Shock

```{r}
rm(list=ls())
library(pls)
library(forecast)
library(car)
library(tseries)
library(rugarch)
library(Dowd)
library(moments)

# Import data
Data_impvol <- read.csv("/Users/benjye/Dropbox/Pricing/Data_R/Data_impvol.csv",
                     header=TRUE, stringsAsFactors = FALSE)

S_all <- Data_impvol[,1]
imp_all <- Data_impvol[,-c(1)]

# Start from 2009
start <- 1
end <- 3000
R_all <- diff(log(S_all))
R_all <- R_all[start:end]
R_sq_all <- R_all^2
imp_all <- imp_all[-nrow(imp_all),]
imp_all <- imp_all[start:end,]

# Split data and normalize it
N_test <- 1000
R_train <- R_all[1:(length(R_all)-N_test)]
imp_train <- imp_all[1:(length(R_all)-N_test),]
R_test <- R_all[(length(R_all)-N_test+1):length(R_all)]
imp_test <- imp_all[(length(R_all)-N_test+1):length(R_all),]

train_data <- cbind(R_train,imp_train)
test_data <- cbind(R_test,imp_test)
train_data <- scale(train_data,center=TRUE,scale=TRUE)
```

```{r}
plot(R_train,type='l')
```

```{r}
adf.test(R_train,k=10)
```

```{r}
plot(R_test,type='l')
```

```{r}
fit <- plsr(formula = R_train~., data=data.frame(train_data), rescale = F, validation="CV",segment.type=c("consecutive"))

fit.cv <- pls::crossval(fit, segments = 10,segment.type = c("consecutive"))
mse_pls <- MSEP(fit.cv)

plot(c(1:20),mse_pls$val[2,1,2:21],'l',xlab='Number of Components',ylab='MSE'
     ,main='MSE vs number of components')

# Find the number of components with minimum MSE
which.min(mse_pls$val[2,1,])
```

```{r}
# Plot scale factors for PLS of R
V <- t(as.matrix(train_data[,2:ncol(train_data)])) %*% 
  as.matrix(train_data[,2:ncol(train_data)]) 
e <- eigen(V)
alpha <- apply(diag(train_data[,1]) %*% 
                as.matrix(train_data[,2:ncol(train_data)]) %*% e$vectors, 2, mean) / e$values
#K: component numbers
f_PLS_1 <- c()
for(K in 2:5){
  w <- sapply(1:K, function(k) sum(alpha^2*e$values^(k+1)))
  W <- matrix(0, K, K)
  for(l in 1:K)
  {
    W[,l] <- sapply(1:K, function(k) sum(alpha^2*e$values^(k+l+1)))
  }
  beta <- solve(W, w,tol = 1e-200)
  temp <- sapply(1:130, function(j) sum(beta*(e$values[j])^(1:K)))
  f_PLS_1 <- rbind(f_PLS_1,temp)
}

par(mfrow=c(2,2))
dev.off()
ms <- c(0.947,0.960,0.971,0.979,0.987,0.995,1.001,1.007,1.014,1.021)
plot(1:10,f_PLS_1[1,1:10],'l',xlab='ms',ylab='scale factor',ylim=c(-0.2,3),main='scale factor (tau = 0.082)',col='black',xaxt = "n")
lines(f_PLS_1[2,1:10],col='blue')
lines(f_PLS_1[3,1:10],col='green')
lines(f_PLS_1[4,1:10],col='red')
#lines(f_PLS_1[5,1:10],col='brown')
abline(h=1,lty='dashed')
legend('topright',lty = c(1,1,1,1),legend=c("2 component","3 component", "4 components","5 components"), col = c("black","blue","green","red"))
axis(1,at=1:10,label=ms)
```

```{r}
# Fit PLS of 2 comp
N_comp <- 2
fit_new <- plsr(formula = R_train~., data=data.frame(train_data),ncomp=N_comp, rescale = F, validation="CV",segment.type=c("consecutive"))

# Find PLS factor of training data
V_pls_train <- as.matrix(fit_new$scores)%*%diag(N_comp)

# Find PLS factor of test data
P_pls <- fit_new$projection

## Normalize test data
imp_norm <- (imp_test - t(t(rep(1,nrow(imp_test))))%*%t(apply(imp_train,2,mean)))/(t(t(rep(1,nrow(imp_test))))%*%t(apply(imp_train,2,sd)))
imp_norm <- imp_norm-rep(1,dim(imp_norm)[1])%*%t(fit_new$Xmeans)

V_pls_test <- as.matrix(imp_norm)%*%as.matrix(P_pls)
```

```{r}
# Decide whether the PLS factors are stationary or not
for(i in 1:N_comp){
  print(adf.test(V_pls_train[,i]))
}
```

```{r}
# Plot the training PLS factor
for(i in 1:N_comp){
  plot(V_pls_train[,i],type='l',xlab='Date',ylab=paste0("PLS factor ",i))
}
```

```{r}
# Normalize PLS factors in training and test data
V_train_norm <- scale(V_pls_train,center=TRUE,scale=TRUE)
V_test_norm <- (V_pls_test - t(t(rep(1,nrow(V_pls_test))))%*%t(apply(V_pls_train,2,mean)))/(t(t(rep(1,nrow(V_pls_test))))%*%t(apply(V_pls_train,2,sd)))

# Combine traing and test data
V_norm <- rbind(V_train_norm,V_test_norm)
```

```{r}
# Plot the normalized PLS factor (training+test)
for(i in 1:N_comp){
  plot(V_norm[,i],type='l',xlab='Date',ylab=paste0("PLS factor ",i))
}
```

```{r}
# ADF test for training+test data
adf.test(V_norm[,1],k=10)
adf.test(V_norm[,2],k=10)
```

```{r}
R_train_norm <- scale(R_train,center=TRUE,scale=TRUE)
R_test_norm <- (R_test-mean(R_train))/sd(R_train)
R_pls <- c(R_train_norm,R_test_norm)
```

PLS on $R^2$.

```{r}
# PLS on R^2
R_sq_train <- R_train^2
R_sq_test <- R_test^2
train_data_2 <- cbind(R_sq_train,imp_train)
test_data_2 <- cbind(R_sq_test,imp_test)
train_data_2 <- scale(train_data_2,center=TRUE,scale=TRUE)

fit2 <- plsr(formula = R_sq_train~., data=data.frame(train_data_2), rescale = F, validation="CV",segment.type=c("consecutive"))

fit2.cv <- pls::crossval(fit2, segments = 5,segment.type = c("consecutive"))
mse_pls2 <- MSEP(fit2.cv)
plot(c(1:20),mse_pls2$val[2,1,2:21],'l',xlab='Number of Components',ylab='MSE'
     ,main='MSE vs number of components')
which.min(mse_pls2$val[2,1,])
```

```{r}
V <- t(as.matrix(train_data_2[,2:ncol(train_data_2)])) %*% 
  as.matrix(train_data_2[,2:ncol(train_data_2)]) 
e <- eigen(V)
par(mfrow=c(2,2))
alpha <- apply(diag(train_data_2[,1]) %*% 
                as.matrix(train_data_2[,2:ncol(train_data_2)]) %*% e$vectors, 2, mean) / e$values
#K: component numbers
f_PLS_2 <- c()
for(K in 2:6){
  w <- sapply(1:K, function(k) sum(alpha^2*e$values^(k+1)))
  W <- matrix(0, K, K)
  for(l in 1:K)
  {
    W[,l] <- sapply(1:K, function(k) sum(alpha^2*e$values^(k+l+1)))
  }
  beta <- solve(W, w,tol = 1e-200)
  temp <- sapply(1:130, function(j) sum(beta*(e$values[j])^(1:K)))
  f_PLS_2 <- rbind(f_PLS_2,temp)
}
```

```{r}
ms <- c(0.947,0.960,0.971,0.979,0.987,0.995,1.001,1.007,1.014,1.021,1.027)
plot(1:11,f_PLS_2[1,1:11],'l',xlab='ms',ylab='scale factor',ylim=c(-0.2,6),main='scale factor (tau = 0.082)',col='black',xaxt = "n")
lines(f_PLS_2[2,1:11],col='blue')
lines(f_PLS_2[3,1:11],col='green')
lines(f_PLS_2[4,1:11],col='red')
lines(f_PLS_2[5,1:11],col='brown')
abline(h=1,lty='dashed')
legend('topright',lty = c(1,1,1,1,1),legend=c("2 components","3 components","4 components","5 components","6 component"), col = c("black","blue","green",'red','brown'))
axis(1,at=1:11,label=ms)
```

```{r}
# PLS with R^2 
N_comp <- 4
fit_new2 <- plsr(formula = R_sq_train~., data=data.frame(train_data_2),ncomp=N_comp, rescale = F, validation="CV",segment.type=c("consecutive"))

V_pls_train2 <- as.matrix(fit_new2$scores)%*%diag(N_comp)

# Find test factors
P_pls2 <- fit_new2$projection
imp_norm <- (imp_test - t(t(rep(1,nrow(imp_test))))%*%t(apply(imp_train,2,mean)))/(t(t(rep(1,nrow(imp_test))))%*%t(apply(imp_train,2,sd)))
imp_norm <- imp_norm-rep(1,dim(imp_norm)[1])%*%t(fit_new2$Xmeans)
V_pls_test2 <- as.matrix(imp_norm)%*%as.matrix(P_pls2)

# Normalize factors
V_norm_train2 <- scale(V_pls_train2,scale=TRUE,center=TRUE)
V_norm_test2 <- (V_pls_test2-t(t(rep(1,nrow(V_pls_test2))))%*%t(apply(V_pls_train2,2,mean)))/(t(t(rep(1,nrow(V_pls_test2))))%*%t(apply(V_pls_train2,2,sd)))

# Combine training and test
V_norm2 <- rbind(V_norm_train2,V_norm_test2)
```

```{r}
V_norm_all <- cbind(V_norm,V_norm2)
write.csv(V_norm_all,'V_norm_all_shock.csv',row.names=FALSE)
```

```{r}
# Plot the normalized PLS factor (training+test)
for(i in 1:N_comp){
  plot(V_norm2[,i],type='l',xlab='Date',ylab=paste0("PLS factor ",i))
  print(adf.test(V_norm2[,i],k=10))
}
```

```{r}
cor(V_norm[,1],V_norm2[,1])
```

```{r}
# Create lag terms for PLS with R^2
lags <- 2
N_train <- nrow(V_norm2)

X_pls_2_all <- V_norm2[(lags+1):N_train,]
X_pls_1_all <- V_norm[(lags+1):N_train,]
for(i in 1:lags){
  if(lags==0){
    break
  }else{
    temp <- V_norm2[(lags+1-i):(N_train-i),]
    temp2 <- V_norm[(lags+1-i):(N_train-i),]
    X_pls_2_all <- cbind(X_pls_2_all,temp)
    X_pls_1_all <- cbind(X_pls_1_all,temp2)
  }
}


R_pls2 <- R_pls[(lags+1):N_train]


# GARCH
spec.eGARCH_pls2 <- ugarchspec(variance.model=list(model="eGARCH",
                    garchOrder=c(1,1),external.regressors = as.matrix(X_pls_2_all[,1:4])), 
                    mean.model=list(armaOrder = c(1,1),include.mean=FALSE,external.regressors =
                                      as.matrix(X_pls_1_all)), distribution.model="sged")
eGARCH_pls2 <- ugarchfit(R_pls2, spec=spec.eGARCH_pls2,out.sample=N_test)
eGARCH_pls2
```

```{r}
# In-sample MSE
sprintf('In-sample MSE is %g',mean((eGARCH_pls2@fit$residuals*sd(R_train))^2))
```

```{r}
# Out-of-sample
forecast_eGARCH_pls2<-ugarchforecast(eGARCH_pls2, data = R_pls2, n.ahead = 1, n.roll = N_test,out.sample =N_test)
sigma_eGARCH_pls2<-sigma(forecast_eGARCH_pls2)
fitted_eGARCH_pls2<-fitted(forecast_eGARCH_pls2)
sprintf('Out-of-sample MSE is %g',mean(((t(fitted_eGARCH_pls2)-R_pls2[(length(R_pls2)-N_test):length(R_pls2)])*sd(R_train))^2))
sprintf('Out-of-sample mean of sd is %g',mean(sigma_eGARCH_pls2))
```

```{r}
mu_train <- fitted(eGARCH_pls2)
mu_train <- drop(coredata(mu_train))
sigma_train <- sigma(eGARCH_pls2)
sigma_train <- drop(coredata(sigma_train))
plot(R_all[1:(length(R_all)-N_test)],type='l',xlab='Date',ylab='Return',col='red')
lines(mu_train*sd(R_train)+mean(R_train),col='blue')
lines(mu_train*sd(R_train)+mean(R_train)+1.96*sigma_train*sd(R_train),col='green4')
lines(mu_train*sd(R_train)+mean(R_train)-1.96*sigma_train*sd(R_train),col='green4')
legend('bottom',lty = c(1,1,1,1),legend=c("Empirical","GARCH", "95% CI","95% CI"), col = c("red","blue","green4","green4"))
```

```{r}
plot(R_all[1600:1800],type='l',xlab='Date',ylab='Return',col='red')
lines(mu_train[1600:1800]*sd(R_train)+mean(R_train),col='blue')
lines(mu_train[1600:1800]*sd(R_train)+mean(R_train)+1.96*sigma_train[1600:1800]*sd(R_train),col='green')
lines(mu_train[1600:1800]*sd(R_train)+mean(R_train)-1.96*sigma_train[1600:1800]*sd(R_train),col='green')
```

```{r}
plot(R_all[(length(R_all)-N_test):length(R_all)],type='l',xlab='Date',ylab='Return',col='red')
lines(t(fitted_eGARCH_pls2)*sd(R_train)+mean(R_train),col='blue')
lines(t(fitted_eGARCH_pls2)*sd(R_train)+mean(R_train)+1.96*t(sigma_eGARCH_pls2)*sd(R_train),col='green4')
lines(t(fitted_eGARCH_pls2)*sd(R_train)+mean(R_train)-1.96*t(sigma_eGARCH_pls2)*sd(R_train),col='green4')
legend('bottomright',lty = c(1,1,1,1),legend=c("Empirical","GARCH", "95% CI","95% CI"), col = c("red","blue","green4","green4"))
```

```{r}
# Autocorrelaiton and heteroscedasticity for residuals
Box.test(eGARCH_pls2@fit$residuals, lag = 10, type = "Ljung")
Box.test(eGARCH_pls2@fit$residuals^2, lag = 10, type = "Ljung")
```

```{r}
# Coverage test 95%
roll_GARCH_pls2<-ugarchroll(spec=spec.eGARCH_pls2, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=253, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.05, keep.coef=TRUE)
report(roll_GARCH_pls2, type="VaR", VaR.alpha = 0.05, conf.level = 0.95) 
```

```{r}
# Coverage test 99%
roll_GARCH_pls2<-ugarchroll(spec=spec.eGARCH_pls2, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=253, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.01, keep.coef=TRUE)
report(roll_GARCH_pls2, type="VaR", VaR.alpha = 0.01, conf.level = 0.99) 
```

```{r}
# Coverage test 90%
roll_GARCH_pls2<-ugarchroll(spec=spec.eGARCH_pls2, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=253, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.1, keep.coef=TRUE)
report(roll_GARCH_pls2, type="VaR", VaR.alpha = 0.1, conf.level = 0.9) 
```

```{r}
# Coverage test 97.5%
roll_GARCH_pls2<-ugarchroll(spec=spec.eGARCH_pls2, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=253, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.025, keep.coef=TRUE)
report(roll_GARCH_pls2, type="VaR", VaR.alpha = 0.025, conf.level = 0.975) 
```

```{r}
# Coverage test 92.5%
roll_GARCH_pls2<-ugarchroll(spec=spec.eGARCH_pls2, data=R_pls2, n.ahead=1, forecast.length=N_test, refit.every=253, solver='hybrid', fit.control = list(stationarity = 1), calculate.VaR=TRUE, VaR.alpha=0.075, keep.coef=TRUE)
report(roll_GARCH_pls2, type="VaR", VaR.alpha = 0.075, conf.level = 0.925) 
```

```{r}
refit_win <- 252
num_iter <- ceiling(N_test/refit_win)
sigma_all <- c()
mu_all <- c()
for(i in 1:num_iter){
  end <- min(length(R_pls2)-N_test + refit_win*i,length(R_pls2)) 
  out_num <- end-(length(R_pls2)-N_test + refit_win*(i-1))-1
  R_pls_temp <- R_pls2[1:end]
  X_pls_1_temp <- X_pls_1_all[1:end,]
  X_pls_2_temp <- X_pls_2_all[1:end,]
  spec.eGARCH_pls2 <- ugarchspec(variance.model=list(model="eGARCH",
                    garchOrder=c(1,1),external.regressors = as.matrix(X_pls_2_temp[,1:4])), 
                    mean.model=list(armaOrder = c(1,1),include.mean=FALSE,external.regressors =
                                      as.matrix(X_pls_1_temp)), distribution.model="sged")
  eGARCH_pls2 <- ugarchfit(R_pls_temp, spec=spec.eGARCH_pls2,out.sample=out_num)
  
  forecast_eGARCH_pls2 <- ugarchforecast(eGARCH_pls2, data = R_pls2, n.ahead = 1, n.roll = 
                                         out_num,out.sample =out_num)
  sigma_eGARCH_pls2 <- sigma(forecast_eGARCH_pls2)
  fitted_eGARCH_pls2 <- fitted(forecast_eGARCH_pls2)
  
  sigma_all <- cbind(sigma_all,sigma_eGARCH_pls2)
  mu_all <- cbind(mu_all,fitted_eGARCH_pls2)
}
```

```{r}
mu_all <- drop(coredata(mu_all))
sigma_all <- drop(coredata(sigma_all))
plot(R_all[(length(R_all)-N_test):length(R_all)],type='l',xlab='Date',ylab='Return',col='red')
lines(mu_all*sd(R_train)+mean(R_train),col='blue')
lines(mu_all*sd(R_train)+mean(R_train)+1.96*sigma_all*sd(R_train),col='green4')
lines(mu_all*sd(R_train)+mean(R_train)-1.96*sigma_all*sd(R_train),col='green4')
legend('bottomright',lty = c(1,1,1,1),legend=c("Empirical","GARCH", "95% CI","95% CI"), col = c("red","blue","green4","green4"))
```

```{r}
R_test_all <- R_all[(length(R_all)-N_test):length(R_all)]
plot(R_test_all[400:550],type='l',xlab='Date',ylab='Return',col='red')
lines(mu_all[400:550]*sd(R_train)+mean(R_train),col='blue')
lines(mu_all[400:550]*sd(R_train)+mean(R_train)+1.96*sigma_all[400:550]*sd(R_train),col='green4')
lines(mu_all[400:550]*sd(R_train)+mean(R_train)-1.96*sigma_all[400:550]*sd(R_train),col='green4')
legend('bottomright',lty = c(1,1,1,1),legend=c("Empirical","GARCH", "95% CI","95% CI"), col = c("red","blue","green4","green4"))
```

```{r}
sigma_GARCH <- sigma_all[6:length(sigma_all)]
sigma_GARCH <- drop(coredata(sigma_GARCH))
sigma_GARCH <- sigma_GARCH*sd(R_train)
sigma_RNN <- read.csv("/Users/benjye/Dropbox/Pricing/Data_R/sigma_RNN.csv",header=TRUE)
sigma_RNN <- sigma_RNN$sigma
VIX <- read.csv("/Users/benjye/Dropbox/Pricing/Data_R/VIX.csv",header=TRUE)
VIX <- VIX$CLOSE
```

```{r}
par(mar=c(5, 4, 4, 6) + 0.1)
start <- 400
end <- 550

plot(sigma_GARCH[start:end], type='l',ylim=c(0,0.04),axes=FALSE, xlab="", ylab="",col="blue",lwd=2)
# lines(sigma_RNN, xlab="", ylab="",col="green4")
axis(2,col="black",las=1)  ## las=1 makes horizontal labels
mtext("Volatility",side=2,line=2.5)
box()

# par(new=TRUE)
# plot(sigma_RNN[start:end], type='l', axes=FALSE, xlab="", ylab="",col="green4",lw=2)

## Allow a second plot on the same graph
par(new=TRUE)

## Plot the second plot and put axis scale on right
plot(VIX[start:end],  xlab="", ylab="", axes=FALSE, type="l", col="black",lwd=2)
## a little farther out (line=4) to make room for labels
mtext("VIX",side=4,col="black",line=4) 
axis(4, col="black",col.axis="black",las=1)

## Draw the time axis
# axis(1,pretty(range(time),10))
mtext("Date",side=1,col="black",line=2.5)  

## Add Legend
legend("topright",legend=c("GARCH","VIX"),lty=c(1,1),col=c("blue","black"))

```

```{r}
par(mar=c(5, 4, 4, 6) + 0.1)
start <- 400
end <- 550

plot(sigma_RNN[start:end], type='l',ylim=c(0,0.04),axes=FALSE, xlab="", ylab="",col="green4",lwd=2)
# lines(sigma_RNN, xlab="", ylab="",col="green4")
axis(2,col="black",las=1)  ## las=1 makes horizontal labels
mtext("Volatility",side=2,line=2.5)
box()


## Allow a second plot on the same graph
par(new=TRUE)

## Plot the second plot and put axis scale on right
plot(VIX[start:end],  xlab="", ylab="", axes=FALSE, type="l", col="black",lwd=2)
## a little farther out (line=4) to make room for labels
mtext("VIX",side=4,col="black",line=4) 
axis(4, col="black",col.axis="black",las=1)

## Draw the time axis
# axis(1,pretty(range(time),10))
mtext("Date",side=1,col="black",line=2.5)  

## Add Legend
legend("topright",legend=c("alphat-RNN","VIX"),lty=c(1,1),col=c("green4","black"))
```
